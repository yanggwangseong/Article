---
title: 프로 파일링과 프레임 그래프
permalink: /wating/2
---

```curl
checks.........................: 100.00% 181 out of 181
     data_received..................: 1.5 MB  8.4 kB/s
     data_received_size.............: avg=7.86s    min=7.76s    med=7.89s    max=7.93s    p(90)=7.93s    p(95)=7.93s   
     data_sent......................: 69 kB   379 B/s
   ✓ dropped_iterations.............: 0       0/s
     http_req_blocked...............: avg=1.42ms   min=604.62µs med=985.08µs max=11.03ms  p(90)=2.32ms   p(95)=3.02ms  
     http_req_connecting............: avg=1.28ms   min=554.41µs med=918.41µs max=10.93ms  p(90)=2.07ms   p(95)=2.69ms  
   ✓ http_req_duration..............: avg=749.45ms min=228.47ms med=832.98ms max=2.07s    p(90)=1.11s    p(95)=1.14s   
       { expected_response:true }...: avg=749.45ms min=228.47ms med=832.98ms max=2.07s    p(90)=1.11s    p(95)=1.14s   
   ✓ http_req_failed................: 0.00%   0 out of 181
     http_req_receiving.............: avg=87.74µs  min=60.58µs  med=78.08µs  max=512.41µs p(90)=108.58µs p(95)=132.41µs
     http_req_sending...............: avg=83.41µs  min=21.95µs  med=71.45µs  max=478.2µs  p(90)=138.04µs p(95)=176.12µs
     http_req_tls_handshaking.......: avg=0s       min=0s       med=0s       max=0s       p(90)=0s       p(95)=0s      
     http_req_waiting...............: avg=749.27ms min=228.36ms med=832.82ms max=2.07s    p(90)=1.11s    p(95)=1.14s   
     http_reqs......................: 181     0.994739/s
     iteration_duration.............: avg=1.75s    min=1.23s    med=1.83s    max=3.07s    p(90)=2.11s    p(95)=2.14s   
     iterations.....................: 181     0.994739/s
     vus............................: 1       min=1          max=3 
     vus_max........................: 30      min=30         max=30

```

2번

```
 ✓ articles status is 200

     checks.........................: 100.00% 180 out of 180
     data_received..................: 1.5 MB  8.4 kB/s
     data_received_size.............: avg=7.86s    min=7.76s    med=7.89s    max=7.93s    p(90)=7.93s    p(95)=7.93s   
     data_sent......................: 69 kB   381 B/s
   ✓ dropped_iterations.............: 0       0/s
     http_req_blocked...............: avg=1.29ms   min=657.91µs med=954.33µs max=9.42ms   p(90)=1.98ms   p(95)=2.16ms  
     http_req_connecting............: avg=1.12ms   min=585.62µs med=886.02µs max=2.78ms   p(90)=1.79ms   p(95)=1.95ms  
   ✓ http_req_duration..............: avg=772.09ms min=225.32ms med=827.6ms  max=1.64s    p(90)=1.09s    p(95)=1.11s   
       { expected_response:true }...: avg=772.09ms min=225.32ms med=827.6ms  max=1.64s    p(90)=1.09s    p(95)=1.11s   
   ✓ http_req_failed................: 0.00%   0 out of 180
     http_req_receiving.............: avg=81.08µs  min=54.5µs   med=76.81µs  max=338.25µs p(90)=100.07µs p(95)=105.61µs
     http_req_sending...............: avg=84.83µs  min=28.25µs  med=72.83µs  max=378.79µs p(90)=135.81µs p(95)=163.94µs
     http_req_tls_handshaking.......: avg=0s       min=0s       med=0s       max=0s       p(90)=0s       p(95)=0s      
     http_req_waiting...............: avg=771.93ms min=225.18ms med=827.29ms max=1.64s    p(90)=1.09s    p(95)=1.11s   
     http_reqs......................: 180     0.998716/s
     iteration_duration.............: avg=1.77s    min=1.22s    med=1.83s    max=2.64s    p(90)=2.09s    p(95)=2.11s   
     iterations.....................: 180     0.998716/s
     vus............................: 1       min=1          max=2 
     vus_max........................: 30      min=30         max=30
```


`jwt 개선 알고리즘을 변경 함`

```
#### (1) **RS256 대신 HS256 알고리즘 사용**

- RS256은 공개 키 기반의 암호화 방식으로, 서명 확인 과정이 **더 많은 CPU 연산을 요구**합니다.
- HS256은 비대칭키 대신 대칭키 기반의 해싱 알고리즘으로, **더 빠르고 CPU 부하가 적습니다**.
- **변경 방법**:
    - JWT 발급 및 검증 시 `algorithm: 'HS256'`을 설정.
```


- 비교 대상 정보들
	- Database 덤프
	- 프로젝트 소스코드
	- k6 부하 테스트 정보
	- 플레임 그래프 정보


# 프로파일링 도구가 많다

- [하이퍼 커넥트에서는 프로파일링 도구로 flamebearer사용](https://github.com/mapbox/flamebearer)  [하이퍼커넥트글](https://hyperconnect.github.io/2020/02/11/Node-cpu-debug.html) 
- https://grafana.com/docs/grafana/latest/panels-visualizations/visualizations/flame-graph/
- https://grafana.com/oss/pyroscope/
- https://grafana.com/docs/pyroscope/latest/configure-client/language-sdks/nodejs/

- **1단계**: Clinic.js로 빠르게 시스템 레벨 및 애플리케이션 병목을 진단.
    - 커널 이벤트, 시스템 콜 등 문제를 확인.
- **2단계**: 애플리케이션 병목이 명확해지면 Pyroscope를 사용해 지속적으로 프로파일링 및 시각화.
    - 함수 호출 경로와 핫스팟(Hotspot)을 분석.
    - Pyroscope는 Clinic.js보다 훨씬 무겁다. 실시간 프로파일링 도구이기 떄문이다.dataDog대신 쓰는거인듯

- k6 + InfluxDB + 그라파나 
- Clinic.js와 Pyroscope 둘다 플레임 그래프 지원
- Clinic.js는 리눅스 환경이라면 perf를 지원한다.
- Pyroscope는 그라파나와 연동이 된다.
	- I/O 디바운스는 확인 안한다. 애플리케이션의 함수호출과 자원량 정도 플레임 그래프로 만듬.
- 프로메테우스는 모니터링 및 알림 시스템, Pyroscope는 플레임 그래프가 목적
- 그라파나 Loki - 로그 모니터링
	- Prometheus 메트릭과 Loki 로그를 결합해 이벤트 원인 파악.
	- Grafana 대시보드에서 로그와 메트릭을 함께 시각화
- Tempo (분산 트레이싱)
	- Jaeger, Zipkin 같은 트레이싱 시스템과 호환되며 Grafana와 통합 가능.
	- 각 요청의 트레이스(경로)를 추적하여 병목을 파악.
	- 요청 A → 서비스 B → 서비스 C의 흐름에서 B와 C 사이의 병목 지점 분석.
	- 트레이싱 데이터를 Grafana에서 시각화.
- Loki + Prometheus + Grafana
	- 메트릭과 로그를 통합해 대시보드에서 분석.
- Tempo + Prometheus + Pyroscope:
	- 메트릭, 분산 추적, 플레임 그래프를 통해 병목 원인 파악.
- OpenTelemetry + Prometheus + Jaeger
	- 메트릭과 트레이스를 표준화하여 데이터 통합.



어떤 부분이 가장 시간이 많이 소비 되는지를 프로파일링 해야된다. 호출할 때 어떤 부분이 가장 시간이 많이 소비 되는지를 프로파일링 해야된다. CPU일 수 도 있고 네트워크 콜에서 I/O를 기다리는걸 수 도 있다. 해당 호출 시간을 통해서 플레임 그래프를 만들어야 한다. Node.js에서 프로파일링 할 수 있는게 필요하고 느리다는걸 측정하기 위해서 어떤 함수가 호출되었을때 이게 얼마나 걸리고 있는지를 플레임 그래프로 그릴 수 있어야 한다.

- CPU Intensive한 코드가 없는지 신경 써줘야해요. 제가 서버 애플리케이션 코드를 작성하다가 종종 만들었던 CPU Instensive한 코드의 예시를 살펴보고 이런 코드를 찾아낼 수 있는 도구인 Clinic.js를 소개할게요.

- CPU Instensive란?
- Stack Trace란?


*노드 프로세스에 프로파일링을 할 수 있는게 필요하고 느리다는걸 측정하기 위해서 CPU 사용률과 어떤 함수가 호출되었을때 이게 얼마나 걸리고 있는지를 플레임 그래프로 그릴 수 있어야 한다*
*DB쿼리가 느린걸 확인 할 수 있는 I/O 작업에 대한것도 플레임 그래프에 나타나야 한다* 


- `findAll 쪽 서브쿼리를 다 없앤 형태로 최적화해서 얼마나 나아지는지` 
- 그래도 크게 개선이 안된다면 클라이언트 쪽에서 API를 분리해서 요청하는게 좋아보인다. 정도로 코멘트 남기기.
- 느려질 수 있는 포인트를 파악해야 한다.
- 많은 테이블에 뮤테이션 할때 데이터 정합성을 테스트 해보기
- 플레임 그래프 + 리스폰스 타임
# Clinic.js

- 정적 프로파일링 도구 입니다.
- Doctor나 Falme등을 동시에 k6와 실행 시킬 수 없다.
## Doctor
- event loop 가 딜레이 되는 시간을 측정하는 도구
- CPU 사용량, 메모리 사용량, 소켓 수를 알 수 있는 도구

## Flame
- 어떤 함수가 가장 오랫동안 CPU를 점유하는지 Flame Graph를 볼 수 있는 도구
- `--kernel-tracing` 오직 리눅스 환경에서만 사용할 수 있지만 `linux_perf` 리눅스 프로파일링 도구를 통해서 커널레벨의 프로파일링도 할 수 있게 해준다.


# K6
- k6로 부하 테스트시에 스레시홀드 설정으로 dropped_iterations를 초과 했을때 Vus가 적은지 확인 해봐야한다. `preAllocatedVUs: 20,` `maxVUs: 100,`  -> `preAllocatedVUs: 100,` `maxVUs: 300,` 

# 문제 발생하는 부분

- 파일명 `75914.clinic-flame.html` 
- `findAll` 과 데이터베이스쪽
- `jwt` 토큰 verify 하는 부분

# 자동화 스크립트

- 배포 서버에서 clinic frame과 `--kernel-tracing` 기능을 이용해서 watching 시킨다.
- 로컬 서버에서 k6로 요청을 보내고 요청이 끝난 후에 ssh로 접속해서 clinic frame을 종료 시키는 명령와 완성된 flame graph를 로컬로 가져오는 명령어를 실행 시킨다. html 파일을 확인해서 분석 한다.

```bash
#!/bin/bash

# 배포 서버 정보
SERVER_USER="user"
SERVER_IP="your-server"
REMOTE_CLINIC_PATH="/path/to/clinic-flame.html"
LOCAL_SAVE_PATH="./clinic-flame.html"

# K6 부하 테스트 실행
echo "Starting K6 load test..."
k6 run --env BASE_URL=http://$SERVER_IP:4000 ./scripts/test.js

# Clinic Flame 프로파일링 종료
echo "Stopping clinic flame on remote server..."
ssh $SERVER_USER@$SERVER_IP "pkill -f 'clinic flame'"

# 결과 HTML 파일 가져오기
echo "Fetching flame graph..."
scp $SERVER_USER@$SERVER_IP:$REMOTE_CLINIC_PATH $LOCAL_SAVE_PATH

echo "Done! Open $LOCAL_SAVE_PATH in your browser to view the flame graph."

```

# 리눅스 배포 환경에서 clinic.js를 구동

- 리눅스에 `perf` 를 먼저 설치 한다.
- clinic을 사용하기 위한 Dockerfile을 작성하고 배포서버에 배포한다.
- 이때 구동을 시키진 않음.
- docker-compose 내에서 볼륨을 통해서 리눅스 perf와 볼륨을 마운트 해준다.
- 로컬 pc에서 k6 부하테스트를 서버에 요청 보낼때 먼저 SSH로 배포 서버에 접속 한후 clinic.js를 docker-compose로 실행 시킨 후 프로파일링 시작 상태를 만든 후에 ssh 접속 종료 로컬의 k6를 실행 시킨다. 부하 테스트가 종료 되면 ssh로 다시 접속해서 clinic.js를 종료 시킨다. 그 후에 생성된 결과 html 파일을 로컬로 가져온다.
# InfluxDB와 그라파나 연결과 태깅으로 구분할때

- 볼륨으로 grafana 폴더를 연동 해두었을때 권한 문제를 잘 체크하라 설정이 변경이 안될 수 있다.
- https://grafana.com/grafana/dashboards/2587-k6-load-testing-results/ - k6와 InfluxDB 와 그라파나 연동 대시보드
- 요청별 구별을 위해서 json 설정파일을 커스텀 한것을 넣어서 대시보드를 추가 해주면 좋다.
- 요청별 구별을 위해서 k6에 `tags: testName` 를 통해서 태그를 넣고 만들어진 대시보드의 설정의 Variables 설정으로 간 후 General에 Name에 `testName` 아래로 내려서 Query 부분에 
- `SHOW TAG VALUES WITH KEY = "testName"` 그럼 이제 testName을 바꿔 가면서 부하 테스트를 하고 나면 대시보드에서 testName으로 구별해서 모니터링 할 수 있다.
- `$testName` `testName::tag` 

# 그라파나 플러그인

- grafana-image-renderer : 패널마다 이미지로 내보내기 가능
- https://grafana.com/docs/grafana/latest/developers/http_api/snapshot/
- 스냅샷 기능 외부로 링크 보낼 수 있음.


# 문서화

```markdown
# Flame Graph Profiling Report

## Overview
This document provides the profiling results of our Node.js application using `clinic.js`'s Flame Graph. It highlights bottlenecks, CPU-intensive functions, and optimization strategies.

## Key Findings
1. **Token Verification**:
   - Function: `verifyToken`
   - Issue: High CPU usage due to synchronous execution (`verify` function from `jsonwebtoken`).
   - Optimization: Refactored to use `verifyAsync` for non-blocking operations.

2. **Database Query**:
   - Query: `findAllV1` in `ArticleRepository`
   - Issue: Multiple `COUNT` subqueries and `JOIN` operations caused delays.
   - Optimization:
     - Added Redis caching for frequent queries.
     - Optimized SQL by reducing unnecessary `JOINs`.

3. **Middleware Performance**:
   - Middleware: `CORS`
   - Issue: Slight overhead from `corsMiddleware`.
   - Optimization: Switched to a lightweight custom CORS middleware.

## Flame Graph Screenshots
- 여기 부분에 ppt로 대체하는게 더 깔끔 할것 같다.
### **Token Verification Hotspot**
![Token Verification](./images/token-verification-flame.png)

### **Database Query Performance**
![Database Query](./images/database-query-flame.png)

## Recommendations
- Refactor CPU-intensive synchronous functions to asynchronous alternatives.
- Cache frequently accessed data using Redis.
- Profile regularly to ensure no regressions.

```

- 구글 ppt 문제가 발생하는 플레임 그래프 스샷
- 문제가 발생하는 코드 부분 스크린샷


# 왜 docker-compose 내부에서

- 왜 docker-compose 내부에서 백엔드와 디비를 함께 돌리면 네트워크 부하가 심할까?
# 알아볼것들

- k6와 클리닉js의 연동 가능성과 시각화가 용이한가?
- k6 결과와 플레임 그래프 어떻게 이전 자료를 관리해야 할까?
- 프로젝트 v1과 v2를 비교하기 위해서 어떻게 나눠두면 좋을까?

2.2 K6 결과와 InfluxDB/Grafana 통합
K6가 제공하는 데이터를 InfluxDB에 저장하면, Grafana를 통해 성능 결과를 동적으로 시각화할 수 있습니다.  
  
실무 활용  
K6의 결과를 매 테스트마다 기록해두고, Grafana에서 버전별 결과를 비교.  
Markdown 문서에 데이터 스냅샷(이미지)와 함께 Grafana 대시보드 링크를 포함.  
2.3 Flame Graph 저장 및 공유  
플레임 그래프는 성능 병목을 시각화하는 데 필수적인 도구입니다. 이를 활용하기 위해:  
  
방법  
플레임 그래프 생성:  
성능 테스트 중 perf나 0x 같은 프로파일링 도구를 사용하여 플레임 그래프 생성.  
SVG/HTML 파일로 저장:  
플레임 그래프를 SVG나 HTML 형식으로 저장하여 공유.  
Markdown에 링크 포함:  
결과 문서에 그래프 파일을 링크로 첨부하거나, SVG 파일을 인라인으로 표시.  
  
플레임 그래프를 html이나 svg로 공유 할 수 있는건 굉장히 문서화 하기 좋을것 같은데  
K6 결과와 InfluxDB/Grafana 통합은 이게 사실 그라파나 대시보드가 띄워져 있는 사이트를 공유 해야 하기 떄문에 썩 마크다운 문서화에 좋아 보이진 않는데 html이나 먼가 svg 같은걸로 이것도 하는 방법 없나요?  
현재 docker-compose 환경에서 그라파나와 k6 influxDB를 연동해둔 상태입니다.


## **1. K6 + InfluxDB + Grafana의 시각화 결과 내보내기**

### **1.1 Grafana 대시보드를 이미지나 PDF로 내보내기**

Grafana는 각 패널 또는 전체 대시보드를 이미지나 PDF로 내보내는 기능을 제공합니다.

#### **방법: 패널 이미지를 내보내기**

1. Grafana 대시보드에서 시각화된 패널을 선택.
2. 패널의 **공유(Share)** 버튼 클릭.
3. **Direct link rendered image** 옵션 선택.
    - 해당 링크를 사용하여 이미지를 다운로드.
4. 이미지를 Markdown 문서에 포함:
    
    markdown
    
    코드 복사
    
    `![K6 Performance](./images/k6-performance-panel.png)`
    

#### **방법: 전체 대시보드를 PDF로 내보내기**

1. Grafana 상단 메뉴에서 **Share Dashboard** 클릭.
2. PDF 내보내기 옵션 선택.
3. PDF 파일을 저장하고, Markdown 문서에 링크로 첨부:
    
    markdown
    
    코드 복사
    
    `[Grafana Dashboard PDF](./docs/k6-performance-dashboard.pdf)`




### **.1 K6 + InfluxDB + Grafana**

- **목적**:
    - InfluxDB에 K6의 성능 테스트 데이터를 저장하고, Grafana에서 InfluxDB를 데이터 소스로 연결하여 시각화.
- **동작 방식**:
    - K6는 `K6_OUT` 환경 변수를 통해 데이터를 InfluxDB로 보냄.
    - Grafana는 InfluxDB에서 데이터를 가져와 대시보드로 시각화.

### **1.2 K6 + Prometheus + Grafana**

- **목적**:
    - Prometheus에 K6의 메트릭 데이터를 푸시하고, Grafana에서 Prometheus를 데이터 소스로 연결하여 시각화.
- **동작 방식**:
    - K6는 Prometheus로 데이터를 직접 푸시하지 않으며, Prometheus **Pushgateway**를 통해 데이터를 전달.
    - Prometheus는 푸시된 데이터를 스크랩(Scrape)하여 저장.
    - Grafana는 Prometheus에서 데이터를 가져와 대시보드로 시각화.

## **3. 두 조합을 동시에 사용할 수 있는지?**

### **동시에 사용 가능**

K6는 다양한 출력 옵션을 지원하므로, 동일한 테스트에서 **InfluxDB**와 **Prometheus**에 데이터를 동시에 전송할 수 있습니다.

#### **K6 환경 변수로 여러 출력 설정**

yaml

코드 복사

`environment:   - K6_OUT=influxdb=http://influxdb:8086/k6, prometheus-pushgateway=http://pushgateway:9091`

#### **동작 흐름**

1. K6는 데이터를 InfluxDB와 Prometheus Pushgateway에 동시에 전송.
2. Grafana는 각각 InfluxDB와 Prometheus를 데이터 소스로 설정하여 시각화.

- 성능 테스트와 시스템 모니터링을 통합하려면 **K6 + InfluxDB + Prometheus + Grafana**를 조합.
- Prometheus는 **테스트 중 실시간 경고**에, InfluxDB는 **장기적 데이터 저장**에 사용.


# 결론
- InfluxDB는 결국 디비 라고 생각하면 된다.
- 그라파나는 추가적인 메트릭스를 추가할 수 있게 해주어서 더욱 디테일하게 모니터링 할 수 있게 도와준다.


## **1. Clinic.js와 K6 조합이 가능한 이유**

1. **Clinic.js**는 애플리케이션 내부에서 발생하는 성능 병목(CPU, 메모리, 이벤트 루프 등)을 분석.
2. **K6**는 외부에서 부하를 가하며 서버의 응답 성능(RPS, 응답 시간 등)을 테스트.
3. 두 도구를 함께 사용하면:
    - K6로 서버에 부하를 가하면서 동시에 Clinic.js로 내부 병목을 분석 가능.
    - 결과적으로 **외부 지표(K6)**와 **내부 지표(Clinic.js)**를 함께 비교하여, 문제의 원인을 더 잘 이해할 수 있음.




# 프로메테우스 연결

```bash
$ npm install @willsoto/nestjs-prometheus prom-client
```

- 해당 두가지 조합을 통해서 메트릭을 수집하고 실시간으로 이제 모니터링 할 수 있는건데 이건 생각 해보면 프로덕션 환경에서 수집을 해서 그걸 그라파나에 시각화 해줄때 필요할것 같고
- 현재 부하테스트가 목적인 나는 k6를 사용하기 때문에 필요 없을것 같다.
- **주요 용도**:
    - 메트릭 수집: 요청 수, 응답 시간, 에러 비율 등 **전체적인 서비스 상태를 모니터링**하는 데 유용.
    - 사용자가 직접 정의한 메트릭(예: 특정 엔드포인트의 호출 수)을 Prometheus로 수집 가능.
- **제한 사항**:
    - **상세한 함수 호출 분석 불가**:
        - 특정 함수가 호출될 때의 시간 소요나 실행 세부 정보를 추적하는 데 적합하지 않음.
    - 함수 레벨 프로파일링보다는 전체적인 서비스 상태와 성능 모니터링에 초점.
- **추천 상황**:
    - 프로덕션 환경에서 서비스 전반적인 상태를 모니터링할 때.
    - 엔드포인트 레벨에서 요청/응답 메트릭을 수집할 때.

## 결론
- 프로메테우스는 프로덕션 환경에서 실시간으로 모니터링 하는것을 목적으로 두는게 좋아보인다. 성능 테스트로 사용하기엔 적합하지 않다.

# Clinic.js 
### **2. Clinic.js**

- **주요 용도**:
    
    - **Node.js 애플리케이션의 내부 프로파일링** 도구로, 플레임 그래프를 통해 병목 구간을 시각적으로 분석 가능.
    - 함수 호출 스택, 이벤트 루프 지연, 메모리 사용 등 **디테일한 실행 정보를 분석**.
- **장점**:
    
    - **플레임 그래프 제공**:
        - 함수 호출 간의 관계와 실행 시간을 시각적으로 표시.
    - 이벤트 루프와 비동기 작업의 병목 구간을 분석.
    - Node.js 특화: NestJS는 Node.js 위에서 동작하므로, Clinic.js가 훨씬 적합.
    - 프로파일링 결과를 HTML, SVG로 저장 가능.
- **추천 상황**:
    
    - 개발 환경에서 특정 함수의 성능 문제를 디버깅할 때.
    - 병목 지점을 플레임 그래프와 같은 시각적인 방법으로 분석할 때.

# Reference

- [당근마켓-김경덕 개발자님 참고](https://www.inflearn.com/courses/lecture?courseId=329811&unitId=137803&tab=curriculum) 