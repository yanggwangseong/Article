---
title: 1장~4장 프로세스와 스레드
permalink: /cs/os/operation-system/1장~4장 프로세스와 스레드
tags:
  - OS
layout: page
---

# Interrupts

> 인터럽트란? 
> 시스템에서 발생한 다양한 종류의 이벤트 혹은 그런 이벤트를 알리는 메커니즘

- 입출력 작업을 시작하기 위해 장치 드라이버는 장치 컨트롤러의 적절한 레지스터에 값을 적재한다.
- 그런 다음 장치 컨트롤러는 이러한 레지스터의 내용을 검사하여 수행 할 작업(예시: 키보드에서 문자 읽기) 을 결정한다.
- 컨트롤러는 장치에서 로컬 버퍼로 데이터 전송을 시작한다.
- 데이터 전송이 완료되면 장치 컨트롤러는 장치 드라이버에게 작업이 완료되었음을 알린다.
- 그런 다음 장치 드라이버는 읽기 요청이면 데이터 또는 데이터에 대한 포인터를 반환하며 운영체제의 다른 부분에 제어를 넘긴다.
- 다른 작업의 경우 장치 드라이버는 "쓰기 완료" 또는 "장치 사용 중"과 같은 상태 정보를 반환한다.
- 근데 이때 컨트롤러는 장치 드라이버에게 작업을 완료 했다는 사실을 알리기 위해 **인터럽트** 를 통해서 이루어진다.

> 하드웨어는 어느 순간이든 시스템 버스를 통해 CPU에 신호를 보내 인터럽트를 발생 시킬 수 있다.
> CPU와 프로세스와 I/O device 서로 통신하는 방법중에 하나이다.

시스템버스 : 주요 구성요소 사이의 통신 경로이다.


1. 중요한 처리 중에 인터럽트 처리를 연기할 수 있어야 한다.
2. 장치의 적절한 인터럽트 핸들러로 효율적으로 디스패치 할 방법이 필요하다.
3. 운영체제가 우선순위가 높은 인터럽트와 우선순위가 낮은 인터럽트를 구분하고 적절한 긴급도로 대응할 수 있도록 다단계 인터럽트가 필요하다.

- 해당 세가지 기능은 *인터럽트 컨트롤러하드웨어* 에 의해 제공된다.

> 대부분의 CPU에는 2개의 언터럽트 요청 라인이 있다.

- nonmaskable interrupt (마스크 불가능 인터럽트)
- maskable (마스킹 가능)

- 인터럽트는 최신 운영체제에서 비동기 이벤트를 처리하기 위해 사용된다.
- 장치 컨트롤러 및 하드웨어 오류로 인해 인터럽트가 발생한다.
- 가장 긴급한 작업을 먼저 수행하기 위해 최신 컴퓨터는 인터럽트 우선순위 시스템을 사용한다.
- 인터럽트는 시간에 민감한 처리에 빈번하게 사용되므로 시스템 성능을 좋게 하려면 효율적인 인터럽트 처리가 필요하다.


# 시스템 콜

- 시스템 콜(System Call)은 사용자 모드(User Mode)에서 운영체제의 기능(커널 기능)에 직접 접근할 수 없도록 설계된 프로그램에서 커널 모드(Kernel Mode)로 전환하여 운영체제 기능을 호출할 수 있도록 해주는 메커니즘입니다. 사용자가 작성한 프로그램에서 운영체제의 자원이나 서비스에 접근해야 할 때 시스템 콜을 사용합니다.
- 시스템콜에 대한 연결고리 역할을 하는 시스템콜 인터페이스를 제공합니다.
- 시스템콜 함수를 호출 했을때 `open`, `wait`, 등 Kernel mode로 전환하여 운영체제 기능을 통해서 작업을 수행하고 작업이 끝나면 그 결과를 리턴 하면서 User mode로 전환 합니다. 
- 시스템 콜이 수행될 때, 시스템 콜은 하드웨어에 의해 하나의 소프트웨어 인터럽트로 취급된다.제어가 인터럽트 벡터를 통해 운영체제 내의 서비스 루틴으로 전달되고, 모드 비트가 커널모드로 설정된다. 시스템 콜 서비스 루틴은 운영체제의 일부이다. 커널은 인터럽트를 발생시킨 명령을 검사하여 어떤 시스템 콜이 발생 했는지를 결정한다.

- 운영체제는 사용자 프로그램이 시스템콜을 사용하여 운영체제의 기능에 접근할 수 있도록 시스템콜 인터페이스를 제공 합니다.
- 시스템콜이란 사용자 프로그램에서 User mode에서 운영체제 기능에 직접 접근 할 수 없기 때문에 Kernel mode로 전환하여 운영체제 기능을 호출 할 수 있도록 해주는 메커니즘입니다.
- 시스템 콜이 수행될 때, 시스템 콜은 하드웨어에 의해 하나의 소프트웨어 인터럽트로 취급 됩니다.
- 제어가 인터럽트 벡터를 통해 운영체제 내의 서비스 루틴으로 전달되고, 모드 비트가 커널모드로 설정됩니다.이때 전환하기 위해서 Trab을 이용 합니다.
- 운영체제 기능에 접근하여 작업이 완료되고 리턴 할때 모드 비트가 유저모드로 설정됩니다.

## System call 종류

- 프로세스/스레드 관련
- 파일 I/O 관련
- 소켓 관련
- 장치(device) 관련
- 프로세스 통신 관련

## Trab

- Trab이란 소프트웨어적으로 발생하는 인터럽트로, 사용자 프로그램이 시스템콜을 호출 할 때 User mode에서 Kernel mode로 전환하기 위해 사용 됩니다.

# 프로그램이란?

- 프로그램이란 컴퓨터가 특정 작업을 수행할 수 있도록 작성된 명령어의 집합입니다. 즉, 실행 가능한 코드의 집합입니다.

# 프로세스란?

> *실행중인 프로그램* 
> CPU 스케줄러가 프로세스들을 멀티 프로그램으로
> 여러개의 프로세스들을 동시에 (concurrent) 실행 시키기 위해서 `timeSharing` 을 한다.
> **운영체제 입장에서는 *작업* 의 단위가 프로세스 단위이다.** 

# 프로세스 메모리

- `텍스트 섹션` 
	- 실행코드
- `데이터 섹션` 
	- 전역 변수
- `힙 섹션` 
	- 프로그램 실행 중에 동적으로 할당되는 메모리
	- 메모리가 동적으로 할당됨에 따라 힙이 커지고 메모리가 시스템에 반환되면 축소된다.
- `스택 섹션`
	- 함수를 호출할 때 임시 데이터 저장장소
	- 함수가 호출될 때마다 함수 매개변수, 지역 변수 및 복귀 주소를 포함하는 *활성화 레코드(activation record)* 가 스택에 푸시 된다.
	- 함수에서 제어가 되돌아오면 스택에서 활성화 레코드가 팝 된다.

> *텍스트 및 데이터 섹션* 의 크기는 고정되기 때문에 프로그램 실행 시간 동안 크기가 변하지 않는다.
> *스택 및 힙 섹션* 프로그램 실행중에 동적으로 줄어들거나 커질 수 있다.

# 프로세스 상태

- New (새로운) : 프로세스가 생성중이다.
- running (실행) : 명령어들이 실행되고 있다.
- waiting (대기): 프로세스가 어떤 이벤트가 일어나기를 기다린다.
	- 입출력 완료 또는 신호의 수신
- ready (준비): 프로세스가 처리기에 할당되기를 기다린다.
- terminated (종료) : 프로세스의 실행이 종료되었다.

# PCB(Process Control Block)

- `프로세스 상태`  : 상태는 new(새로운), ready(준비), running(실행), waiting(대기), halted(정지)
- `프로그램 카운터(PC)` : 프로그램 카운터는 이 프로세스가 다음에 실행할 명령어의 주소를 가리킨다.
- `CPU 레지스터들`  : 프로그램 카운터와 함께 이 상태 정보는, 나중에 프로세스가 다시 스케줄 될 때 계속 올바르게 실행되도록 하기 위해서 인터럽트 발생 시 저장되어야 한다.
- `CPU 스케줄링 정보` : 이 정보는 프로세스 우선순위, 스케줄 큐에 대한 포인터와 다른 스케줄 매개변수를 포함한다.
- `메모리 관리 정보` : 기준(base) 레지스터와 한계(limit) 레지스터의 값, 운영체제가 사용하는 메모리 시스템에 따라 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함한다.
- `accounting(회계)정보` : CPU 사용시간과 경과된 실시간, 시간제한, 계정 번호, 잡 또는 프로세스 번호 등을 포함한다.
- `입출력 상태 정보` : 이 정보는 이 프로세스에 할당된 입출력 장치들과 열린 파일의 목록 등을 포함한다.


# 프로세스 상태와 PCB 그리고 컨텍스트 스위칭

> 키워드 : 프로세스 상태, PCB, 프로세스 스케줄링, 컨텍스트 스위칭

> 프로세스가 생성 되면 바로 ready (준비) 상태로 간다.
> CPU 스케줄러에 의해서 자신의 차례가 되면 즉, Scheduler dispatch 된다면 Running 상태가 되고 여러가지 작업들을 처리하게 됩니다.
> 자신에게 할당된 타임슬라이스를 다 쓰게 된다면 다시 Ready 상태로 돌아간다
> 이렇게 ready 상태와 running 상태를 왔다 갔다 하다가 running 상태에서 I/O 작업 요청이 들어 오게 되면 
> waiting 상태가 되고 I/O 작업이 끝나기를 기다립니다.
> I/O 작업이 끝나게 되면 다시 ready 상태로 돌아가게 됩니다.
> ready 상태에서 다시 자신의 차례가 되면 running 상태로 변하게 되고 작업들을 처리하게 됩니다.
> running 상태에서 작업이 마무리 되면 프로세스가 종료가 되면서 terminated 상태가 됩니다.

- 프로세스 상태
- PCB
- 프로세스 스케줄링
- 컨텍스트 스위칭


# 프로세스간통신(IPC)

# IPC 통신이 왜 필요 할까요?
- IPC란 협력적인 프로세스들이 데이터를 교환 즉, 서로 데이터를 보내거나 받을 수 있는 통신 기법 입니다.
- IPC (Interprocess Communication)가 필요한 이유는, 각각의 프로세스는 독립적인 메모리 공간을 가지고 있기 때문입니다. 프로세스는 각각 TEXT, DATA, STACK, HEAP 영역을 따로 가지며, 이러한 메모리 자원은 다른 프로세스와 기본적으로 공유되지 않습니다.
- 독립된 프로세스들 간에 데이터를 교환하고 협력할 수 있도록 도와주는 통신 수단이 IPC통신 입니다.

# Interprocess Communication(IPC)

- 메세지를 전달하는 방법
	- message passing : *커널* 을 통해 메세지 전달
- 주소 공간을 이용하는 방법
	- shared memory
		- *커널* 에게 shared memory를 사용한다는 시스템 콜요청을 한다.
		- 서로 다른 프로세스 간에도 일부 주소공간을 공유하게 하는 shared memory 메커니즘

- thread : thread는 사실상 하나의 프로세스 이므로 프로세스 간 협력으로 보기는 어려우나 동일한 Process를 구성하는 thread들 간에는 주소공간을 공유하므로 협력 가능하다.

## 공유 메모리 시스템에서의 프로세스간 통신

## 메세지 전달 시스템에서의 프로세스간 통신

### Message system

- 프로세스 사이에 공유 변수(shared variable)를 일체 사용 하지 않고 통신하는 시스템

### Direct Communication

- **커널을 통해서 메세지 전달**
- 통신하려는 프로세스의 이름을 명시적으로 표시
- `send(P, message)` - 프로세스 P에 메세지를 전송한다.
- `receive(Q, message)` - 프로세스 Q로부터 메세지를 수신한다.


### Indirect Communication

- **커널을 통해서 메세지 전달**
- `mailbox(또는 port)` 를 통해 메세지를 전달.
- `send(A, message)` - 메세지를 메일박스 A로 송신한다.
- `receive(A, message)` - 메세지를 메일박스 A로부터 수신한다.

## Synchronization (동기화)

- Blocking send : 송신하는 프로세스는 메세지가 수신 프로세스 또는 메일박스에 의해 수신될때 까지 `Blocking` 된다.
- NonBlocking send : 송신하는 프로세스가 메세지를 보내고 작업을 재개한다.
- Blocking receive : 메시지가 이용 가능할 때까지 수신 프로세스가 Blocking된다.
- NonBlocking receive : 송신하는 프로세스가 유효한 메세지 또는 널(null)을 받는다.


**blocking , non-blocking** : **synchronous, asynchronous** 

- blocking, non-blocking : *응답*에 관한것이다.
	- Blocking: 요청을 보내고 응답이 올때까지 기다리는것을 의미합니다. 이 동안은 다른 작업을 수행 할 수 없습니다.
	- Non-blocking: 요청을 보내고 다른작업을 재개하다가, 응답이 도착하면 그때 처리합니다. 즉, 응답 대기 중에도 다른 작업을 할 수 있습니다.
- synchronous, asynchronous : *상태*에 관한것이고 상태의 동기화 여부에 관한 것이다.
	- synchronous : 요청한 작업에 대해 완료 상태 여부에 따라 순차적으로 처리 하는것이다. 즉, 요청한 작업에 대해 상태가 동기화 되어서 순차적으로 처리 된다.
	- asynchronous : 요청한 작업에 대해 완료 상태 여부와 상관없이 다음 작업을 진행합니다. 즉, 요청한 작업에 대해 상태가 동기화 되지 않고 자신의 작업을 수행합니다.


# IPC 시스템 사례

- Shared Memory : `POSIX` Shared Memory
	- `POSIX` : UNIX 계열 운영 체제 간의 호환성을 높이기 위해 표준화된 인터페이스를 정의
- Message Passing : `Pipes` 
	- 파이프는 초기 UNIX 시스템에서 제공하는 IPC 메커니즘중 하나였다.
## POSIX Shared Memory

- POSIX Shared Memory는 `memory-mapped file` 파일을 사용하여 구현된다.
	- `memory-mapped file` 은 Shared Memory의 특정 영역을 연관시킨다.
- 프로세스는 먼저 아래와 같이 `shm_open()` 시스템 콜을 사용하여 Shared Memory 객체를 생성해야 한다.
	- `fd = shm_open(name, O_CREATE | O_RDWR, 0666)` 
- 객체의 크기를 바이트 단위로 설정한다.
	- `ftruncate(fd, 4096)` 
- 마지막으로 `mmap()` 함수가 Shared Memory 객체를 포함하는 `memory-mapped file` 을 구축 한다.
	- `mmap()` 함수는 공유 메모리 객체에 접근할 때 사용될 `memory-mapped file` 포인터를 반환한다.

## Pipes (Message Passing)

- `Pipes` 
	- 파이프는 프로세스간에 통신하는 더 간단한 방법의 하나이지만 통신할 때 여러 제약을 한다.

- 파이프를 구현 할 때 4가지 고려사항
	- 파이프가 `unidirectional(단방향)` 또는 `bidirectional(양방향)` 통신을 허용 할것인가?
	- `bidirectional(양방향)` 통신이 가능하다면, `half duplex(반이중)` 방식인가, `full duplex(전이중)` 방식인가?
		- half duplex(반이중) : 한순간에 한 방향 전송만 가능.
		- full duplex(전이중) : 동시에 양방향 데이터 전송이 가능.
	- 통신하는 두 프로세스 간에 *부모-자식* 과 같은 특정 관계가 존재해야만 하는가?
		- 구현의 편의상 부모-자식 관계를 가져야 한다.
	- 파이프는 네트워크를 통하여 통신이 가능한가
		- 파이프는 네트워크에서 사용하지 않고 네트워크에서 사용하는 파이프를 *socket* 이라고 한다.

### Ordinary Pipes (일반 파이프)
- Ordinary pipes는 파이프를 생성한 프로세스 이외에는 접근할 수 없다.
- 부모 프로세스가 파이프를 생성하고 `fork()` 로 생성한 자식 프로세스와 통신하기 위해 사용한다.
- producer(생산자)-consumer(소비자) 형태로 두 프로세스 간의 통신을 허용한다.
	- producer(생산자) : 한 종단에 쓴다. (write end)
	- consumer(소비자) : 다른 종단에서 읽는다 (read end)
- `unidirectional(단방향)통신` (one-way): Ordinary pipe는 한쪽으로만 데이터를 전송할 수 있으며 오직 단방향 통신만 가능하다.
- `bidirectional(양방향)통신`(two-way) : 양방향 통신을 하려면 2개의 파이프를 사용하면 된다.

### Named Pipes (지명 파이프)

- 양방향 통신을 지원한다.
- 부모-자식 관계를 필요로 하지 않는다.
- 여러 프로세스들이 Named Pipe를 통해서 통신 할 수 있다.
- Named Pipe는 다수의 write를 가진다.
- 통신 프로세스가 종료하더라도 Named Pipe는 계속 존재하게 된다.


# 클라이언트 서버환경에서 통신

- Communication in Client-Server Systems

## Socket (소켓)

- socket은 통신의 극점(endpoint)을 뜻한다.
	- 컴퓨터를 특정할 때  `IP address` 
	- 컴퓨터와 컴퓨터를 연결하는 파이프를 특정 해야 하는데 이것을 `port` 이라고 한다.
	- IP address와 port를 하나로 묶으면 `socket` 이 된다.

## RPC (원격 프로시저 호출)

- 소켓의 스레드 간에 구조화되지 않은 바이트 스트림만을 통신하도록 하기 때문에 이러한 원시적인 바이트 스트림 데이터를 구조화하여 해석하는것은 클라이언트와 서버의 책임이 된다.
	- 클라 32bit 서버 64bit일때 이 바이트 스트림 데이터를 구조화하여 해석하는것은 클라이언트와 서버에서 처리해야 되기 때문에 굉장히 번거롭다
- 이것을 개선하기 위해 등장한 높은 수준의 통신 기법인 원격 프로시저(remote procedure call, RPC)이다.
- 네트워크에 연결된 두 시스템 사이의 통신에 사용하기 위하여 프로시저 호출 기법을 추상화하는 방법으로 설계 되었다.
- 클라이언트는 원격 호스트에서 프로시저를 호출하는데, 이는 마치 로컬에서 프로시저를 호출하듯이 수행된다.

### RPC System

- RPC 시스템은 클라이언트쪽에 **스텁** 을 제공하여 통신을 하는데 필요한 자세한 사항들을 숨겨 준다.
- 원격 프로시저마다 다른 스텁이 존재한다.
- 클라이언트가 원격 프로시저를 호출하면 RPC는 그에 대응하는 스텁을 호출하고 원격 프로시저가 필요로 하는 매개변수를 건네준다.
- 그러면 스텁이 원격 서버의 포트를 찾고 매개변수를 **marshall(정돈)** 한다.
- 서버측의 스텁(stub)은 클라이언트로부터 메세지를 수신한 후, 메세지에 포함된 직렬화된 매개변수를 `marshalled` 하고, 서버에서 요청된 프로시저를 실행한다.
- 필요한 경우 반환 값들도 다시 `mershalled` 하여 다시 되돌려준다.

# 쓰레드란?

- **CPU 관점에서 스레드는 작업을 처리하는 실행단위 입니다** 
- 스레드 ID, 프로그램 카운터(PC), 레지스터 집합, 스택으로 구성된다.
- 스레드는 같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션 등 자원들을 공유 하지만 개별적인 스택 영역을 가집니다.
- 실제로 프로그램이 실행되어서 메모리에 올라가 프로세스가 되면 pid를 가지게 되고 CPU를 할당 받아 작업을 처리하게 되는데 거기에 그 작업의 실행 단위가 쓰레드이고 쓰레드는 tid를 가지게 된다.
- 쓰레드도 프로세스 상태와 같은 단계를 가지고 있다. ( new, running, waiting, ready, terminated )

# Single Thread Process vs Multi Thread Process

![](/assets/thread01.png)


- Single-thread
- Multi-thread

# Multi Thread Programming 장점

- responsiveness (응답성)
- resource sharing (자원 공유)
- economy (경제성)
- scalability (규모 적응성)

# Multicore Programming

- Multi Programming
	- CPU 사용률을 극대화 시키는게 목적
	- 메모리에 여러 프로그램을 올려서 실행
	- 단점으로는 하나의 프로세스가 CPU를 오래 점유하면 Blocking 된다.
- Multi Tasking
	- 프로세스의 응답 시간을 최소화 시키는데 목적
	- 아주 짧은 One time quantum으로 교대로 실행되기 때문이다.
	- 시분할 (Time sharing) 방식을 사용해 마치 프로그램이 동시에 실행되는 것처럼 느껴지게 만든다.
- Multi Thread
	- 하나의 프로세스가 동시에 여러 작업을 실행하는데 목적
- Multi Processing
	- 두개이상의 프로세서나 코어를 활용하는 시스템

## Core란?

- CPU에내에서 명령어를 처리하고 실행하는 독립적인 단위이다.
- 쓰레드 단위의 작업을 *Parallel* 로 처리 할 수 있게 합니다.
- 코어 수가 많을수록 Parallel 처리가 가능해져 전체 처리 속도가 빠릅니다.

## Multicore Programming이 왜 필요 했을까?

> 옛날 운영체제에서는 Single Core System을 사용하여 여러 작업을 처리했는데, 이는 time-sharing 방식을 통해 여러 작업을 빠르게 교체하며 마치 동시에 실행되는 것처럼 순차적으로 처리했습니다. 그러나 하나의 작업이 CPU를 오래 점유하게 되면 다른 작업들은 Blocking 상태가 되어 시스템의 응답 속도가 느려지는 문제가 발생했습니다.
> 이 문제를 해결하기 위해 Multi Core System이 등장했습니다. Multi Core System은 하나의 CPU에 여러 개의 코어를 포함하고 있어, 각 코어가 독립적으로 작업을 병렬(Parallel)로 처리할 수 있습니다. 이를 통해 CPU 자원을 더 효율적으로 사용하고, 작업 간의 Blocking 문제를 줄여 시스템의 응답 속도를 크게 개선할 수 있었습니다.

### Single Core System vs Multicore System

#### Single Core

- Single Core Cpu는 하나의 코어만 있기 때문에 한번에 하나의 작업만 처리할 수 있습니다.
- 여러 작업이 있을 경우, 시분할(time-sharing) 방식을 사용하여 각 작업에 짧은 시간을 교대로 할당해 처리 합니다.
- 이로 인해 작업들이 순차적으로 실행되며, 마치 동시에 실행되는 것처럼 보일 수 있지만 실제로는 빠르게 교대하는 방식입니다.
- 그래서 하나의 작업이 CPU를 오래 점유하게 되면 다른 작업들은 Blocking 되어 대기하게 됩니다.

#### Multi Core

- Multi Core CPU는 하나의 CPU 칩에 여러개의 코어가 포함되어 있습니다.
- 각 코어가 독립적으로 작업을 수행할 수 있어, 여러 작업을 Parallel(병렬)적으로 실행할 수 있습니다.

## MultiCore Programming이란?

> multi core를 더 효율적으로 사용하여 concurrency 향상시키는 기법

- `Single-Core` System
	- **Concurrent(병행)** 실행
	- 단지 처리 코어가 한번에 하나의 스레드만 실행할 수 있기 때문에 Concurrent은 시간이 지남에 따라 쓰레드 실행이 `interleaved` 됨을 의미한다.
		- interleaved : 아래의 그림처럼 스레드 작업을 사이사이 끼워 넣는다라는 뜻이다.

![](/assets/thread02.png)

- `Multi-Core` System
	- **Parallel(병렬)** 실행
	- 시스템이 각 코어에 별도의 스레드를 할당할 수 있기 때문에 일부 스레드가 Parallel로 실행될 수 있음을 의미한다.

![](/assets/thread03.png)

- *Concurrent system* : 모든 작업이 진행되게 하여 둘 이상의 작업을 지원한다.
- *Parallel system* : 둘 이상의 작업을 동시에 수행할 수 있다.

### 결론

> 멀티 쓰레드라고 병렬처리를 하는것이 아니다.

- Single Core System에서는 시분할 처리(Time sharing)을 통해서 Concurrent(병행)를 한다.
- Multi Core System에서 각 코어에 별도의 스레드를 할당할 수 있기 때문에 Parallel(병렬)가 가능하다.

## 코어 수를 무작정 많이 늘리는 것이 좋을까?

### Amdahl의 법칙

- 전체 프로그램에서 병렬화 할 수 없는 부분이 성능 개선의 한계가 됩니다. 즉, 프로그램 내에서 병렬화가 불가능한 부분이 존재할 경우, 코어 수를 늘려도 이 부분에서 **병목 현상** 이 발생합니다.
- 예를 들어, 프로그램의 80%는 병렬로 실행할 수 있지만 나머지 20%는 병렬화가 불가능하다면, 코어 수를 늘려도 그 20%가 성능을 제한하는 요소로 남게 됩니다.

> Amdahl의 법칙이란, 프로그램 내에서 병렬화할 수 없는 부분이 성능 개선에 한계를 만든다는 법칙입니다. 코어 수를 N개 무한정 늘리더라도 프로그램 내 병렬 처리할 수 있는 부분과 병렬 처리할 수 없는 부분이 존재합니다. 예를 들어, 프로그램의 80%는 병렬 처리가 가능하지만, 나머지 20%는 병렬로 처리할 수 없다고 가정해 봅시다. 이 경우 아무리 코어를 늘리더라도 병렬화할 수 없는 20%의 부분 때문에 전체 프로그램의 성능 향상에는 한계가 생깁니다.
> 즉, 코어를 늘리면 병렬 처리 가능한 부분의 성능은 향상되겠지만, 병렬화할 수 없는 부분이 프로그램 성능의 병목이 되어 성능 개선이 제한됩니다. Amdahl의 법칙은 이러한 점에서 "코어를 무작정 많이 늘리는 것이 반드시 성능 향상으로 이어지지 않는다"는 것을 설명합니다. 결국, 병렬 처리할 수 없는 부분 때문에 성능 개선에는 한계가 있으며, 이를 고려하지 않고 코어를 늘리기만 한다면 오히려 비효율적일 수 있습니다.


# Types of Parallelism

## Data Parallelism (데이터 병렬성)

- 동일한 데이터의 부분집합을 다수의 계산 코어에 분배한 뒤 각 코어에서 동일한 연산을 실행하는데 초점을 둔다.
- 예를 들어 0~10의 배열의 내용을 더하는 경우를 생각 해보면 멀티코어 시스템에서 코어0에서 스레드A는 `[0]~[5]` 까지 더하고 코어1에서 스레드 B는 `[6]~[10]` 까지 더할 수 있다. 이때 두 스레드는 각자 병렬로 실행된다.

## Task Parallelism (태스크 병렬성)

- 태스크(스레드)를 다수의 코어에 분배한다. 각 스레드는 고유의 연산을 실행한다.
- 예를 들어 0~10 배열의 내용을 더하는 경우 통계 연산을 수행하는 2개의 스레드가 필요할 수 있다. 멀티코어 시스템에서 코어0에서 스레드 A는 배열의 합을 계산하고 코어1에서 스레드 B는 배열의 평균을 계산할 수 있다. 이때 스레드들은 병렬로 실행된다.


# Multithreading Models

## User-Level Thread

- User-Level Thread의 스케줄링은 애플리케이션에 의해 관리되며, 운영 체제는 이러한 스레드의 존재를 인식하지 못합니다.
- 스레드의 생성, 삭제, 스케줄링 등을 운영체제가 아닌 라이브러리가 처리합니다.
- **운영체제는 스레드를 인식하지 못하므로, 프로세스 단위로 스케줄링 됩니다** 
- **하나의 스레드가 블록되면 해당 스레드가 속한 전체 프로세스가 Blocking 됩니다** 

### 특징

- 스레드 생성, 종료, 스위칭이 빠르며, 커널 모드 전환 비용이 없습니다.
- 운영체제가 스레드를 지원하지 않거나, 커널 모드로 전환하지 않고 스레드를 관리해야 하는 경우 사용.

## Kernel-Level Thread

- Kernel-Level Thread는 프로세스 스케줄링을 그대로 적용가능 합니다.
- Kernel-Level Thread는 스케줄링은 운영 체제에 의해 직접 관리되며, 운영 체제는 각 스레드에 CPU 시간을 할당합니다.
- **한 스레드가 Blocking 되어도 다른 스레드가 실행될 수 있습니다** 

### 특징

- 멀티코어 시스템에서 스레드를 병렬(Parallel) 실행할 수 있어 성능이 향상됩니다.
- 하나의 스레드가 블록되더라도 다른 스레드가 실행 가능하여 블로킹 문제를 해결


## 종류

- User Thread가 CPU에서 실행되려면 Kernel Thread와 반드시 연결돼야 한다.
- User Thread와 Kenel Thread를 연결 시키는 방법 3가지

1. Many-To-One Model
	- 스레드 관리는 사용자 공간의 스레드 라이브러리에 의해 행해진다.
	- User Thread간의 컨텍스트 스위칭이 빠르다.
	- 멀티 코어 활용 못한다.
	- 한 스레드가 Block되면 모든 스레드들이 Blocking된다.
2. One-to-One Model
	- 스레드 관리를 OS에게 위임한다.
	- 스케줄링도 커널이 수행하게 된다.
	- 멀티 코어 활용으로 Parallel(병렬성)을 제공한다.
3. Many-to-Many Model

# Threads 라이브러리
- POSIX Pthreads
- Windows
- Java

# Implicit Threading (암묵적 스레딩)

- Multi Core System에서 Concurrent(병행) 및 Parallel(병렬)응용의 설계를 도와주는 방법으로 스레딩의 생성과 관리 책임을 응용 개발자로부터 컴파일러와 실행시간 라이브러리에게 넘겨주는것

## Thread pool

- 프로세스를 시작할 때 아예 일정한 수의 스레드들을 미리 풀로 만들어 두는것이다.

## Thread pool 장점

1. 새 스레드를 만들어 주기 보다 기존 스레드로 서비스 해주는것이 종종 더 빠르다.
2. 스레드 풀은 임의 시각에 존재할 스레드 개수에 제한을 둔다. 이러한 제한은 많은 수의 스레드를 병렬 처리할 수 없는 시스템에 도움이 된다.
3. 태스크를 생성하는 방법을 태스크로부터 분리하면 태스크를 실행을 다르게 할 수 있다.
	- 예를 들어 태스크를 일정 시간 후에 실행되도록 스케줄 하거나 혹은 주기적으로 실행시킬 수 있다.

## Fork Join

- explicit threading(명시적 스레딩)이라고 하지만 implicit threading(암묵적 스레딩)에도 사용될 수 있다.

## Open MP

- 병렬로 실행될 수 있는 블록을 찾아 **parallel regions(병렬 영역)** 이라고 부릅니다.
- 응용 개발자는 자신들의 코드 중 **parallel regions(병렬 영역)** 에 compiler directives를 삽입한다.
- 해당 directive는 OpenMP 실행시간 라이브러리에 해당 영역을 *parallel(병렬)* 로 실행하라고 지시한다.


# Thread Cancellation (스레드 취소)

- asynchronous cancellation (비동기식 취소) : 스레드가 업데이트를 수행하는 중이라도 스레드를 즉시 중지한다.
- deferred cancellation (지연 취소) : 스레드에 종료해야 한다고 통지하지만 스레드는 질서 정연하게 종료된다. 대부분 비동기 종료보다 지연 취소가 선호된다.

# Linux 스레드

- Linux는 프로세스와 스레드를 구분하지 않는다. 대신 각각을 태스크라고 한다.
- Linux `clone()` 시스템 콜을 사용하여 프로세스와 더 비슷하거나 스레드와 더 비슷한 태스크를 만들 수 있다.