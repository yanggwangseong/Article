---
title: PART5 저장장치및 인덱싱
permalink: /cs/database/database-system-7th/PART5 저장장치및 인덱싱
tags:
  - Database
layout: page
---

# DiskBlockAccess

- 각 I/O요청은 디스크의 디스크 식별자와 논리 블록 번호로 구성된다.
- 디스크 블록에 대한 요청
	- 순차적 접근
	- 임의 접근

1. 버퍼링(Buffering)
	- 다음에 있을 요청을 충족하기 위해 디스크로부터 읽는 블록을 메모리 버퍼내에 임시로 저장하는 기법
2. Read-ahead (미리 읽기)
	- 디스크 블록에 접근할 때, 블록에 대한 요청이 없더라도 동일 트랙내의 연속적인 블록을 일단 메모리 내의 버퍼로 읽어 들이는 기법이다.
3. Scheduling (스케줄링)
	- FCFS(First-Come First-Served)
		- 디스크큐에 들어온 순서대로 요청을 처리
	- SSTF(Shortest Seek Time First)
		- 디스크큐에 들어온것중에서 현재 헤드의 위치에 가장 가까운 요청을 먼저 서비스 하는 기법
	- Scan
		- 처리 할 수 있는 접근 수를 최대한 증가시키는 방식으로 트랙 접근 순서를 정하려고 한다.
		- 엘리베이터 알고리즘
		- SSTF와 같은 방법으로 운영되지만 차이점은 **'진행 방향'** 상의 가장 짧은 거리에 있는 요청을 서비스하는 기법이다.
	- C-Scan
	- Look
4. File organization (파일 구성)
	- 블록 접근 시간을 줄이기 위해 데이터에 접근하고자 하는 방식에 가장 가까이 부합하는 방식으로 디스크의 블록을 조직할 수 있다.
5. Nonvolatile write buffer (NVRAM, 비휘발성 쓰기 버퍼)
	- 디스크 쓰기 속도를 높이기 위한 목적
	- 메인 메모리 같은 경우 휘발성 메모리이기 때문에 트랜잭션 처리 시스템 같은 갱신 중심 데이터베이스 응용 프로그램에서는 NVRAM을 통해서 이를 해결한다.

- HDD와 SSD 차이점
- HDD와 SSD의 Access 방식

# 디스크

**데이터베이스 시스템에서 하드웨어의 특성과 그것이 데이터베이스 성능에 어떤 영향을 주는지**를 이해하는 것이 핵심

1. 저장 장치 계층(Storage Hierarchy)
2. 자기 디스크(Magnetic Disk)의 구조와 동작
3. 디스크 성능 요소
4. Flash Memory의 특성
5. RAID (Redundant Array of Inexpensive Disks)
6. 디스크 스케줄링 알고리즘
7. 디스크 블록 접근 최적화 전략

- 저장 장치 계층
	- **속도와 비용의 트레이드오프**
	- cache
	- main memory
	- flash memory
	- magnetic disk
	- optical disk
	- magnetic tapes
- Magnetic Disk
	- **디스크 동작 방식**
	- 플레터
	- 트랙
	- 섹터
		- **디스크로부터 읽고 쓸 수 있는 정보의 가장 작은 단위** 
	- 암
	- read-write 헤더
	- 실린더
		- **모든 디스크 판위에 있는 헤드는 다같이 움직이기 때문에 여러개의 판의 헤더들은 같은 트랙을 가리킨다. 이를 실린더라고 한다.** 
		- 모든 디스크 판의 `i` 번째 트랙을 `i` 번째 실린더라 부른다.
	- Spindle (스핀들)
	- disk controller (디스크 컨트롤러)
		- 컴퓨터 시스템과 디스크 드라이브의 하드웨어를 연결하는 역할을 한다.
		- **섹터를 읽고 쓰기 위한 명령어를 수용해서 디스크 암을 정확한 트랙에 이동시켜서 실제 데이터를 읽고 쓰는 행동을 한다.** 
		- error detection
			- checksum (체크섬)
			- **remapping of bad sector(손상된 섹터의 재배치)** 
				- 섹터의 손상을 감지 했다면 논리적으로 이 섹터를 다른 물리적 위치에 배치 한다.
- Disk Performance 측정
	- **디스크의 우수성은 용량, 접근시간, 데이터 전송 속도와 신뢰성** 
	- 디스크의 특정 섹터에 있는 데이터에 접근 과정
		- access 하기 위해서 암을 정확한 트랙 위로 이동한 후 스핀들로 회전하면서 해당 섹터가 이 암 아래에 나타날 때까지 기다린다.
	- access time (접근 시간)
		- **읽기나 쓰기 요청을 받았을때 데이터가 전송되기 시작할 때까지의 시간** 
	- seek time (탐색 시간)
		- **디스크 암(disk arm)을 정확한 트랙으로 이동시키는 데 걸리는 시간** 
	- sequential access (순차적 접근)
		- 연속적인 요청은 같은 트랙 혹은 인접트랙에 있는 연속적인 블록 번호에 대한 것이다.
	- random access (랜덤 접근)
		- 연속적인 요청은 디스크상에 있는 랜덤의 블록에 대한것이다.
		- IOPS(I/O operations per second) : 초당 I/O 연산 수
			- **디스크에서 초당 가능한 랜덤 블록 접근수는 접근 시간, 블록 크기 및 디스크의 데이터 전송 속도에 따라 다르다** 
	- MTTF(mean time to failure)
		- 평균적으로 시스템이 아무 실패 없이 계속해서 동작할 수 있는 시간이다.
- **Flash memory**
	- NOR Flash와 NAND Flash
	- NAND Flash는 데이터 저장 장치에 주로 사용되는 특이 케이스다.
		- NAND Flash
		- NAND Flash는 플래시에서 **읽기**는 4킬로바이트 단위 데이터의 **page(페이지)** 단위로 읽는다.
		- NAND Flash의 페이지는 Magnetic Disk의 Sector와 유사한 개념이다.
		- SSD는 NAND Flash를 사용하여 만든다.
			- **SSD는 블록 지향 인터페이스를 제공한다** 
				- 이를 통해서 HDD처럼 데이터를 블록 단위로 저장 장치가 다룰 수 있게 한다.
	- **Flash memory에서 write(쓰기)**
		- **플래시 메모리에서 쓰기 후에 다시 쓰기시에 overwrite(덮어쓰기)를 할 수 없다** 
		- **erase(지우고)** 이어서 다시 쓰기를 해야한다.
		- **플래시 메모리는 보통 지울 수 있는 횟수가 제한되어 있다** 
	- **동작 원리**
		- 플래시 메모리 시스템은 논리적 페이지 주소를 물리적(실제) 페이지 주소에 **mapping(매핑)** 함으로써 느린 지움 속도와 갱신 횟수 제한으로 인해 받는 영향을 최소화한다.
			- **Address Mapping이 왜 필요할까?**
				- Flash memory의 write와 erase로 인한 갱신 횟수제한과 속도를 개선하기 위해서
				- 즉, **논리 주소와 물리 주소를 매핑해서 새 위치에 쓰고 테이블만 업데이트** 
			- 어떻게?
				- 논리적 페이지를 수정하면 이미 지운 물리적 페이지에 다시 대응해야 하고
				- 나중에 기존 위치에 있는 데이터를 지워야 한다.
				- 각 물리적 페이지는 자신의 논리적 주소를 저장한 메모리의 작은 부분을 차지한다.
				- 만약 논리적 주소를 다른 물리적 주소로 다시 대응하면, 원래의 물리적 주소는 삭제된것으로 간주한다.
				- 그러므로 물리적 페이지를 스캔하여 각 논리적 페이지가 어디에 남아 있는지 찾을 수 있다.
				- 신속한 접근을 위해, 논리적 페이지의 **물리적 페이지 대응 정보 (logical-to-physical mapping, L2P)** 는 메모리내 **translation table(변환 테이블)** 로 복제된다
			- EX) 예시
				- 처음
					- 논리 주소 0 -> 물리 주소 A
				- 데이터 수정 발생
					- 논리 주소 0 -> (overwrite 불가) -> 새 물리 주소 B에 저장
						- 변환 테이블 갱신 : 논리 주소 0 -> 물리 주소 B
						- 물리 주소 A는 삭제된 것으로 간주한다.
		- 플래시 메모리는 다수의 삭제된 페이지를 포함하는 블록을 주기적으로 지우는데, 먼저 그 블록 내에 있는 지우지 않은 페이지를 다른 블록에 복사한다.
			- (이때 translation table은 그러한 안 지운 페이지에 대한 정보를 갱신한다.)
			- 각 물리적 페이지는 주어진 갱신 횟수 범위 안에서만 갱신될 수 있으므로, 여러 번 지워졌던 물리적 페이지에는 거의 갱신되지 않는 데이터라는 의미가 있는 **cold data** 가 할당되고
			- 반면에 많이 지워지지 않았던 페이지는 자주 갱신되는 데이터라는 의미가 있는 **hot data** 가 저장된다.
			- **wear leveling(평등화 작업)** 
				- 물리적 블록에 걸쳐서 골고루 지움 연산을 분포시키는 원리
				- 플래시 메모리 컨트롤러가 작업을 수행한다.
				- 플래시 메모리 컨트롤러가 wear leveling(평등화 작업)을 하는 이유는?
					- 지우고 쓰기의 오버헤드와 지우기 횟수제한을 최적화 하기 위한 address mapping을 사용 했을 때 계속적으로 물리적 페이지에 쓰다보면 한번은 평등화 작업을 해줘서 지우기를 해줘야해서
	- 플래시 변환 계층 (flash translation layer)
		- flash translation layer에서 모든 동작을 수행한다.
		- 파일 시스템과 데이터베이스 저장 장치 구조는 저장 구조에 대한 같은 논리적 뷰를 제공한다.
			- 논리적 뷰(Logical View)란?
				- 저장 장치를 어떻게 인식하고 다루는지를 **추상화** 한 관점이다.
				- 즉, 파일 시스템/데이터베이스 시스템이 저장 장치를 바라보는 관점을 사용자에게 논리적 뷰를 제공 할 수 있다.
				- 어떻게 가능할까?
					- 플래시와 마그네틱 저장 장치가 같은 페이지/섹터 지향 인터페이스를 가지기 떄문이다.
	- SSD의 성능
		- 복수의 랜덤 요청을 병렬로 처리 할 수 있고 32개의 병렬 요청을 동시에 지원한다.
			- **Magnetic Disk는 불가하다. 즉, 이것이 SSD가 HDD보다 빠른 이유가 된다** 
			- HDD에서는 왜 여러 랜덤 요청을 병렬처리 할 수 없을까?
				- 데이를 읽고 쓰기 위해선 Read/Write 헤더가 섹터에 위치하고 스핀돌이 동작 하면서 해당 하는 섹터에 위치 했을 때 비로서 데이터를 읽거나 쓸 수 있기 때문이다.
				- 판위에 여러개의 헤더들은 다같이 움직이기 때문이 즉, 실린더라는 그룹으로 동작하기 때문이다.
- hybrid disk drive (하이브리드 디스크 드라이브)
	- 캐시 메커니즘을 사용하여 플래시 메모리를 캐시처럼 사용하여 작은 플래시 메모리에 마그네틱 저장 장치를 결합한 디스크 시스템이다.
	- SAN 및 NAS 시스템에서 사용
		- SSD를 HDD에 있는 데이터의 캐시로 사용하도록 설정 할 수 있다.
- **RAID**
	- **💡 언제 사용할까?** 
	- 디스크의 성능과 신뢰성 향상을 위한 디스크 아키텍쳐
	- 중복에 의한 신뢰성 향상
	- 병렬화에 의한 성능 향상
- **Disk Block Access** 
	1. 버퍼링(Buffering)
		- 다음에 있을 요청을 충족하기 위해 디스크로부터 읽는 블록을 메모리 버퍼내에 임시로 저장하는 기법
	2. Read-ahead (미리 읽기)
		- 디스크 블록에 접근할 때, 블록에 대한 요청이 없더라도 동일 트랙내의 연속적인 블록을 일단 메모리 내의 버퍼로 읽어 들이는 기법이다.
	3. Scheduling (스케줄링)
		- FCFS(First-Come First-Served)
			- 디스크큐에 들어온 순서대로 요청을 처리
		- SSTF(Shortest Seek Time First)
			- 디스크큐에 들어온것중에서 현재 헤드의 위치에 가장 가까운 요청을 먼저 서비스 하는 기법
		- Scan
			- 처리 할 수 있는 접근 수를 최대한 증가시키는 방식으로 트랙 접근 순서를 정하려고 한다.
			- 엘리베이터 알고리즘
			- SSTF와 같은 방법으로 운영되지만 차이점은 **'진행 방향'** 상의 가장 짧은 거리에 있는 요청을 서비스하는 기법이다.
		- C-Scan
		- Look
	4. File organization (파일 구성)
		- 블록 접근 시간을 줄이기 위해 데이터에 접근하고자 하는 방식에 가장 가까이 부합하는 방식으로 디스크의 블록을 조직할 수 있다.
	5. Nonvolatile write buffer (NVRAM, 비휘발성 쓰기 버퍼)
		- 디스크 쓰기 속도를 높이기 위한 목적
		- 메인 메모리 같은 경우 휘발성 메모리이기 때문에 트랜잭션 처리 시스템 같은 갱신 중심 데이터베이스 응용 프로그램에서는 NVRAM을 통해서 이를 해결한다.


# 파일

- 파일이란?
- 블록이란?
	- **Disk를 논리적으로 나눈 단위**
- 페이지란?
	- **데이터베이스 시스템에서 Disk 블록을 관리하기 위해 사용하는 논리적인 단위** 
	- DBMS에서 디스크 블록을 추상화하여 페이지라는 단위를 사용하여 관리함으로써 확장성이 좋아졌다.
	- 왜 이렇게 사용하나?
		- DBMS와 OS가 독립적으로 데이터를 접근하게 만들어서 각기 다른 DBMS마다 페이지를 정의 할 수 있습니다.
		- 이를 통해서 여러가지 File 레코드를 구성 할 수 있게 됩니다.
- 레코드란?
- Fixed-Length Records (고정 길이 레코드)
	- **💡 언제 사용할까?** 
	- 각 레코드가 동일한 크기를 가진다. 고정된 크기의 필드들로만 구성한다.
	- 예를 들어 레코드 길이가 53바이트이면 첫번째 레코드부터 N번째 레코드까지 다 53바이트를 차지한다.
	- 문제점
		- 문제점1) 블록 크기가 53의 배수가 되지 않는다면 몇몇 레코드는 블록 경계를 넘게된다.
			- 즉, 하나의 레코드가 하나의 블록에 저장되지 않게되어 해당 레코드를 읽을때 두개의 블록에 모두 접근 해야 한다.
			- 해결방법)
				- 한 블록에 완전히 채울 수 있는 만큼의 블록만 레코드를 할당한다.
					- 어떻게?
						- 블록 크기를 레코드 크기로 나눠서 계산하여, 소수 부분은 무시하면 된다.
							- 예시) 블록 크기/ 레코드 크기 했을때 몫만큼만 블록에 할당하면 되는것 같다. 나머지가 발생하면 그건 다음 블록의 첫번째 레코드가 되는것 같다.
		- 문제점2) **레코드를 삭제하기가 어렵다** 
			- 해결방법1) 삭제할 레코드가 차지하는 공간은 그 파일의 다른 레코드로 채우는 방법을 사용
				- 한 레코드를 삭제할 때 이 레코드 뒤에 있는 모든 레코드를 바로 전 레코드가 차지한 공간으로 이동시킨다.
					- 단점) 많은 수의 레코드가 이동해야 한다.
				- 삭제한 레코드가 있었던 공간에 파일의 마지막 레코드를 이동하는게 쉬울 수 도 있다.
				- **레코드 이동은 추가적인 블록접근이 필요해서 바람직하지 않다** 
			- 해결방법2) 그 공간을 무시할 수 있도록 레코드를 삭제 했다는 표시를 해야한다.
				- **삽입할 레코드가 있을경우 이용 가능 공간을 찾기가 어렵다** 
	- **고정 길이 레코드 문제점 해결을 위한 추가적인 구조** 
		- 파일 앞부분에 일부 바이트를 할당해 **file header(파일 헤더)** 를 만든다.
		- 파일 헤더 정보
			- **내용이 삭제된 첫번째 레코드의 주소** 
			- **해당 첫번째 레코드의 주소를 사용해서 이용가능한 다음 레코드의 주소를 저장한다** 
			- 레코드 주소는 레코드의 위치를 가리키므로 해당 주소를 **포인터** 로 생각할 수 있다.
			- 연결 리스트를 형성
			- **만약 삽입시에 헤더를 통해서 이용가능 공간을 찾는데 없을경우 파일 끝에 새로은 레코드를 추가한다** 
- Variable-Length Records
	- **💡 언제 사용할까?** 
	- 가변 길이 레코드가 필요한 상황
		- 문자열과 같은 가변 길이 필드가 있을 때
		- 배열 혹은 multiset과 같은 반복적인 필드를 포함하는 레코드 유형과 파일 내에 여러 유형의 존재가 있을경우
	- 여러 기법에서 해결 해야 하는 문제 2가지
		- 속성이 가변 길이인 경우에도 개별 속성을 쉽게 추출할 수 있는 방식으로 하나의 레코드를 표현하는 방법
		- 블록 내의 레코드를 쉽게 추출할 수 있도록 블록 내에 가변 길이 레코드를 저장하는 방법
	- 기법
		- 레코드
			- 레코드 처음 부분에서 길이와 위치 표시
				- 레코드 처음부분에서 **offset과 length** 쌍으로 가변길이 Attribute들의 위치와 길이를 표시한다.
				- 이후 고정 길이 속성들의 값을 연속적으로 저장한다.
				- 그 이후 가변 길이의 속성들의 값을 저장한다.
			- Null bitmap 방식
				- 값이 Null인 속성에 1바이트만 차지하게 Null bitmap을 사용
		- 페이지
			- slotted-page structure
				- 블록의 시작에 헤더가 포함하는 정보
					- 헤더에 있는 레코드 엔트리의 수
					- 블록에서 빈 곳의 끝
					- 각 레코드의 위치와 크기를 포함하고 있는 엔트리 배열
	- InnoDB에서 가변길이 레코드를 어떻게 관리하나요?
		- InnoDB는 Slotted Page 구조를 사용해 레코드를 관리하며, 레코드마다 헤더를 두어 트랜잭션 정보, NULL 비트맵, 가변 길이 정보를 포함시킵니다. VARCHAR나 TEXT 같은 필드는 길이에 따라 페이지 내 또는 외부에 저장되고, 외부 저장 시 포인터만 남겨둡니다. 또한, 레코드 오프셋은 페이지 끝의 슬롯 디렉터리에 저장되어 효율적인 탐색이 가능합니다.
- **파일 레코드 구성 방법** 
	- **Heap file organization (힙 파일 구성)**
		- 순서와 상관없이 레코드를 파일 내의 아무 위치에나 저장하는 방식입니다.
		- **💡 언제 만들고 싶은지? 언제 쓰면 좋을까? 언제 사용할까?** 
			- 순서가 보장되지 않아도 되고 삽입/삭제가 잦은 상황에서 사용.
			- 로그 테이블 파일을 구성할때 사용하면 좋을것 같습니다.
				- 새로운 로그가 삽입되고 오래된 로그는 주기적으로 삭제를 하며 잦은 삽입과 삭제가 일어나기 때문이다.
		- 배열 형태의 메타데이터 파일로 저장되어 관리된다.
			- 배열의 인덱스 -> 블록 번호, 배열의 값 -> free-space map
		- 속도는 빠르지만 정렬 기반 탐색에는 부적절
		- 갱신
			- 삭제 후 빈곳에 저장하는게 좋은데 DBMS에서 파일의 모든 블록을 순차적으로 검색하지 않고도 빈곳이 있는 블록을 효율적으로 찾을 수 있어야 한다.
		- 데이터베이스 시스템 -> 블록을 추상화한 페이지 단위의 논리적인 단위를 통해서 힙 파일 생성 -> OS 파일 시스템이 데이터베이스 시스템이 만든 힙 파일을 Disk의 블록에 저장한다.
		- Free-Space Map이란?
			- 데이터베이스에서 빈곳이 있는 블록을 효율적으로 찾기 위한 자료구조
			- 빈곳을 어떻게 구할까?
				- Free space map값/각 블록에 최대 사용 가능한 비트값
				- 예를 들어 블록마다 3bit씩 사용한다고 가정하면 3bit로 표현할 수 있는 값은 2의 3승인 8개의 값만 가능하다.
					- free-space map값 / 8을 한 값이 남은 공간으로 표현 할 수 있다.
		- 2단계 free-space map이란?
			- free-space map이 너무 커질경우 매우 느려지기 때문에 예를 들어 100개단위로 나누어서 해당 100개의 그룹의 최대 free-space값을 저장하는 2단계 free-space map을 만든다.
			- 만약 4개가 있다면 free-space map은 총 400개가 있는것이고 여유 있는 공간을 찾기 위한 탐색 시간을 1/100으로 소요된다.
	- **Sequential file organization (순차 파일 구성)**
		- **💡 언제 사용할까?** 
		- Search Key 기준으로 데이터를 정렬하여 저장하는 파일 구조
		- 레코드가 정렬된 상태에서 검색이 자주 발생하는 경우 사용
		- 물리적으로 **검색 키 값 순서대로 저장되며, 레코드들은 포인터로 연결될 수 있음** 
		- 삭제
			- 포인터 체인 방식으로 삭제를 관리한다.
		- 삽입
			- Search Key 순서로 볼때 삽입할 레코드 바로 앞에 위치하는 레코드를 파일에서 찾는다.
			- 찾은 레코드와 같은 블록 내에 빈 레코드(즉 삭제한 후 빈 공간)가 있다면 거기에 새로운 레코드를 삽입한다.
			- 없는경우 **overflow block** 에 새로운 레코드를 삽입한다. 레코드를 Search Key 순서로 연결하기 위해 포인터를 조정한다.
		- 잦은 반복이 되게 되면 overflow block에 레코드가 계속 삽입되면서 포인터만 조정하는 방식이 된다면 실제 물리적으로 저장하는 물리적 순서와 Search Key순서가 달라지게 된다.
		- 이를 해결하기 위해서 다시 물리적으로 순차적인 순서가 되도록 파일을 **reorganized(재구성)** 해야한다.
		- **순차 파일 구조는 삽입/삭제가 적고 정렬된 접근만 필요한 정적 데이터에 사용** 
		- **언제 만들고 싶은지? 언제 쓰면 좋을까?** 
			- 데이터가 정적인 순서가 정렬되고 삽입/삭제가 거의 발생하지 않고 조회와 Range Query만 발생하는 대한민국 도시 테이블을 저장할때 사용 할것 같습니다.
	- **Multitable Clustering file organization(다중 테이블 군집 파일 구성)** 
		- **💡 언제 사용할까?** 
		- **여러 다른 릴레이션의 레코드가 같은 파일에 저장하는 구성** 
		- cluster key라는 함께 저장되는 레코드를 정의하는 속성을 통해서 저장한다.
		- 조인은 빠르나 개별 쿼리는 느려질 수 있다.
			- 왜?
				- 릴레이션마다 파일에 저장 했을때 튜플의 개수가 적은 테이블을 조회 할 때 3번만 조회할것을 조인되어 저장된 파일 튜플을 전부 조회 해야(100번) 되는 경우
	- B+-트리 파일 구성 (B+- tree file organization)
	- 해싱 파일 구성 (Hashing file organization)
- Data-Dictionary Storage ✅
	- **system catalog** 라고도 한다.
	- Query가 실행되기 전에, 필요한 테이블/인덱스/컬럼 등의 **메타데이터 정보** 를 저장하는 스토리지
	- 시스템 메타데이터에 자주 접근 하기 때문에 인메모리 데이터 구조에 올려둔다.
		- 인메모리 데이터 구조란?
			- 데이터 베이스 시스템에서 사용하는 메인 메모리상의 논리적 캐시를 말합니다.
			- 종류)
				- **버퍼풀(데이터 페이지)** 
				- **Data-Dictionary Storage Cache (메타데이터)** 
				- 쿼리 캐시
			- 메인 메모리에서 사용하기 위해서 데이터베이스 시스템에서 구현한 **논리적인 캐시 데이터 구조** 
				- 예시) 하드웨어 캐시 CPU (L1, L2, L3 캐시), 소프트웨어 캐시(DBMS 버퍼풀, Data-Dictionary Storage Cache)
			- 소프트웨어 캐시라는것은 결국 특정한 자료구조(LRU캐시 등) 를 통해서 자주 사용하는것들을 메인 메모리에 저장하여 자주 사용하는 메타데이터를 접근 하는 방식을 말합니다.
	- 정보 정류
		- 릴레이션 이름
		- 각 릴레이션 속성의 이름
		- 속성의 도메인과 길이
		- 데이터베이스에 대해 정의한 뷰의 이름과 이 뷰에 대한 정의
		- 무결성 제약조건
		- 사용자 이름, 권한, 비밀번호 등
- **⭐️ Database Buffer** 
	- 가상메모리 메커니즘 같은 느낌이다.
	- 메인 메모리에 크기가 큰 데이터베이스를 다 올릴 수 없는 문제가 있다.
	- **데이터베이스 시스템의 주요 목적은 디스크와 메모리 사이에 블록의 전송 수를 최소화하는 것** 
	- **Buffer란?** 
		- **디스크 블록의 복사본을 저장하기 위해 이용할 수 있는 메인 메모리의 일부분이다.**
		- 메인 메모리에서 **일부분을 차지하는 공간** 이고 임시 저장소다.
	- 데이터 베이스시스템에서 복사본 다루는 방법
		- 하드웨어
			- RAID 아키텍쳐
		- 소프트웨어
			- 메인 메모리 Buffer
	- **Buffer manager란?**
		- 버퍼 공간의 할당을 책임지고 있는 시스템
		- 데이터베이스 시스템 내의 프로그램은 디스크로부터 블록을 가져올 필요가 있을 때 Buffer manager를 호출한다.
		- 요청 블록이 버퍼에 있는 경우
		- 요청 블록이 버퍼에 없는 경우
			- 버퍼에 블록을 저장하기 위한 공간을 할당하는데 이때 공간을 만들기 위해 메모리에 있는 블록을 디스크로 보내기도 한다. **(스와핑)** 
			- 보내진 블록은 디스크에 쓰인 가장 최근것과 비교해서 변경된 것이 있으면 다시 디스크에 덮어쓰기 한다.
			- 버퍼 관리자는 디스크로부터 요구된 블록을 버퍼에 읽어 와서 메인 메모리의 블록 주소를 블록을 요청한 해당 프로세스에 전달한다
	- **버퍼에 고정된 핀 블록**
		- concurrent process를 방지하기 위해서 프로세스가 버퍼 블록으로부터 데이터를 읽기 전에 블록을 쫒아내지 않는 것이 중요하다.
		- 프로세스는 블록을 고정시키는 **pin(핀)** 연산을 실행한다.
			- 버퍼 관리자는 핀 블록을 제거하지 못한다.
		- **데이터 읽기가 끝나면 프로세스는 고정을 해제하는 unpin(언핀)연산을 실행** 하여 필요할 때 블록을 제거할 수 있도록 한다.
		- 여러 프로세스가 **pin** 연산과 **unpin** 연산을 수행 하는 경우 각 버퍼 블록의 **pin count** 를 계산하고 유지하는 방법을 사용한다.
			- pin연산시 카운트를 증가시키고 unpin연산시 카운트를 감소시킨다.
			- **버퍼 페이지는 핀수가 0인 경우에만 제거될 수 있다** 
	- **버퍼 Shared Locks과 Exclusive Locks**
		- **페이지에서 추가하거나 삭제하는 프로세스는 페이지 내용을 이동할 필요가 있다**
		- 이때 다른 프로세스도 페이지의 내용을 읽으면 안된다.
		- Lock을 위한 규칙
			- (TODO)
	- 버퍼 블록의 출력과 강제 출력
		- Buffer Block output이란?
			- 버퍼 공간이 필요한 경우 Replacement Strategy를 통해서 핀 되어 있지 않은 블록을 제거하는것을 말한다.
		- Buffer Block forced output이란?
			- 데이터를 일관성 있게 하기 위해서 동시성 제어 시스템으로 부터 트랜잭션이 commit 되는 경우
	- **버퍼 Replacement Strategy (18장,19장 언급)**
		- **목적** 
			- 디스크 접근을 최소화하기 위해서이다.
		- LRU(least recently used, 가장 오래전에 사용된 페이지를 제거)
			- 다음에 참조 할 블록
		- MRU(most recently used, 가장 최근에 사용된 페이지를 제거)
			- 재참조 할 마지막 블록
			- **마지막 튜플을 처리한 후 핀블록을 unpin한 블록이 최근에 가장 많이 사용한 블록** 
				- 예시) 마지막 튜플을 처리하고 나면 다시 마지막 튜플에 접근하지 않을 확률이 더 높기 때문에 가장 최근에 사용된 버퍼 페이지를 replacement 한다.
				- Join 구문을 생각 해보았을때 버퍼 페이지에 A와 B를 조인 한다고 했을때 B의 마지막 튜플이 처리되고 나면 그다음 참조될 가능성이 높은 페이지는 다시 재참조될 B의 첫번째 튜플이다.
				- 그러므로 LRU방식으로 교체하게 되면 Disk I/O가 발생한다.
		- 실제 블록 교체를 위한 최적의 전략은 **MRU(most recently used)** 방식이다.
			- **가장 최근에 참조를 어떻게 알 수 있나?** 
				- pin연산과 unpin연산
		- 교체되지 않아야 하는 정보
			- Data-Dictionary 메타데이터 정보
			- 데이터 파일에 대한 인덱스
		- 블록 교체 전략의 다른 요인
			- **언젠가 그 블록을 다시 참조하리라는 것보다 다른 요인에 의해 더 영향을 받는다** 
			- (CH18) 동시성 제어 시스템이 동시에 여러 사용자의 요청을 처리하고 있다면 데이터베이스의 일관성을 유지하기 위해서 어떤 요청은 미뤄질 수 있다.
				- 동시성 제어 시스템으로부터 어느 요청이 지연되고 있다는 것을 가리키는 정보를 버퍼 관리자에게 주면, 이 정보를 이용해서 버퍼 관리자는 블록 교체 방법을 변경할 수 있다.
			- (CH19) 충돌 복구 서브시스템은 블록 교체에 엄격한 제약 조건을 부과한다.
				- 어떤 블록을 변경했을 때 버퍼 관리자는 버퍼에 있는 블록의 최신 버전을 디스크에 다시 써서는 안된다.
- **⭐️ column-oriented storage**
	- 각 속성(field)을 별도의 파일에 저장한다.
	- **많은수의 튜플에서 특정 속성에만 접근하는 데이터 분석 쿼리에 매우 적합하다** 
	- 이유
		- 감소한 I/O : 필요한 속성만 읽어와서 I/O가 감소한다.
		- CPU 캐시 성능이 향상
		- 압축이 효율적이다
		- 벡터 처리
	- 단점
		- 튜플 재구성 비용
		- 튜플 삭제 및 갱신 비용
		- 압축 해제 비용
	- **OLAP(Online Analytical Processing)에 사용** 
		- 대량의 데이터를 신속하게 분석하고, 복잡한 쿼리를 실행하는 기술
	- ORC와 Parquet
		- 열기반 파일 형식
	- ORC는 행지향 형식을 열지향 형식으로 변환한다.
		- 튜플 순차는 **stripe(스트라이프)** 라고 하는 열 기반 표현으로 나뉜다.
		- ORC 파일에는 여러개의 스트라이프가 존재하며, 각 스트라이프의 크기는 250메가바이트정도이다.
	- 사용예시) Google BigQuery, data-warehousing
- **⭐️ main-memory database**
	- 모든 데이터가 메모리에 상주하는 데이터베이스다.
	- **Buffer manager가 없다** 

# 인덱스

- Ordered index
- **Hash index**
- Clustering index
- NonClustering index
- Dense index
- Sparse index
- Index update
	- Insertion
		- Dense index case
		- Sparse index case
	- deletion
		- Dense index case
		- Sparse index case
- **B+ 트리 Balanced 유지방법**
	- 적어도 반은 차야된다.
- B+트리 인덱스
	- Root Node
	- Leaf Node
	- NonLeaf Node
- B+트리 삽입과 삭제
- B+트리 갱신 비용
- BST vs B+트리 사용하는 이유
	- BST는 Balanced인 경우와 달리 Non-Balanced인 경우 탐색 속도가 O(n)으로 이진 탐색의 장점을 효율적으로 사용 할 수 없다.


## B+트리 파일

**💡인덱스 순차파일 구조는 왜 파일이 커지면서 성능이 감소할까?** 

- B+트리 파일구조
	- 오버플로블록에 레코드를 저장하게 되는 문제
	- 갱신이 B+트리 인덱스와 동일하게 동작하고 Split, Merge, 재분배등을 활용한다.
	- **B+ 트리 인덱스나 파일구조에서 트리상에서 인접한 Leaf node가 디스크상의 서로 다른 위치에 있을 수 있다는 점에 주의 해야한다** 
	- 레코드 집합에 대해 파일 구조를 새로 생성할 때에는 트리상에서 서로 인접한 Leaf node에 디스크상에서 최대한 가까이 위치한 블록을 할당하는 것이 가능하다.
		- **그래서 Leaf node에 대한 순차 검색은 디스크에 대한 순차 검색에 근접하다** 
		- **그러나 삽입과 삭제가 일어남에 따라 순차성이 감소하고, Leaf node에 대한 순차 검색은 디스크 탐색을 점점 더 많이 필요로 하게 된다** 
			- 이를 위해서 순차성을 복원하기 위해서는 인덱스 재구축이 필요하다.
- 보조 인덱스와 레코드 재배치
	- **B+ 트리 파일 구조는 레코드가 갱신되지 않아도 레코드의 위치를 바꿀 수 있다.** 
	- 어렵군. 세컨더리 인덱스 갱신을 고비용 연산으로 문제라서 이러한 문제를 해결하기 위한 방법 소개
- **문자열 인덱싱**
	- **문자열 값을 갖는 속성에 대해 B+트리 인덱스를 생성하는 것은 두가지 문제가 있습니다** 
		- 첫번째) 문자열이 가변 길이를 가질 수 있다는것이다.
		- 두번째) 문자열이 길 경우 팬아웃이 적어지고 따라서 트리 높이가 증가한다는 것이다.
			- 검색 키의 길이가 가변적이면 꽉 차 있는 서로 다른 노드도 서로 다른 팬아웃을 가질 수 있다.
			- 이 경우 노드가 꽉 차면, 즉 새로운 엔트리를 추가할 공간이 없으면 노드에 Search 엔트리가 몇개 들어 있든 상관없이 노드를 **Split(분할)** 해야 한다.
			- 또한 노드를 Merge(합병)하거나 엔트리를 재분배 할 때도 노드가 가질 수 있는 최대 엔트리 수를 기준으로 하지말고, 노드에서 사용되는 공간의 비율을 기준으로 해야한다.
	- **즉, 고정 길이 인덱싱을 사용 했을 때는 Search Key 레코드가 각각의 노드에 동일한 개수의 엔트리를 가질 수 있는데 반면 가변 길이를 가지는 문자열 인덱싱은 각각의 노드에 동일하지 않은 엔트리를 가지게 되면서 트리의 깊이가 깊어진다** 
		- 고정 길이 인덱싱
			- 팬아웃이 일정하게 유지된다
		- 가변 길이 인덱싱
			- 팬아웃이 일정하지 않다.
			- **트리 깊이가 깊어지고 뿐만 아니라 특정 인덱스를 탐색, 갱신 속도가 빠른부분이 있거나 느린부분이 생기면서 성능이 일정하지 않다.**
	- **prefix compression(접두어 압축)** 이라는 기술을 이용해 노드의 팬아웃을 늘릴 수 있다.
		- 어떻게?
			- non leaf node에 모든 search key를 저장하는것이 아닌 검색에 필요한 부분만 저장 하는것이다.
				- 예시) 특정 노드 "Silberschatz" 라는 search key를 저장할때 서브트리가 2개 "Silas" 와 "Silver"라면 전체를 저장하는게 아닌 "Silb" 까지만 저장해도 충분하다.
- **Fanout(팬아웃)이란?**
	- **한 노드의 포인터 수를 그 노드의 팬아웃이라고 한다**  
- **💡 Autoincrement 로 int형으로 pk를 구성한 인덱스 B+트리 레코드는 고정길이 레코드로 구성될것이고 UUID인 문자열로 구성된 B+트리 레코드는 가변길이 레코드로 구성** 
- B+트리 인덱스의 벌크로딩
	- **(B+트리의 트리의 높이는 대용량의 테이블에 대해서도 5 또는 그 미만이다)** 
	- 대용량의 릴레이션에 B+트리를 구축하는 케이스
		- 비클러스터링 인덱스를 릴레이션에 구축한다고 가정
			- 왜?
				- 릴레이션이 메인 메모리보다 매우 크고 인덱스 역시 메인 메모리보다 크기 때문에
		- 이때 릴레이션을 스캔하고 엔트리를 B+트리에 추가할 때 엔트리의 특정 순서가 존재하지 않기 떄문에 접근하는 각 leaf node는 접근될 때마다 데이터베이스 버퍼에 없을 수 있다.
			- 왜 없을 수 있을까?
				- 블록에 랜덤하게 정렬된 순서로 접근하면 매번 엔트리가 leaf node에 추가될 때마다 디스크 탐색으로 단말 노드를 포함하는 블록을 불러와야 한다.
				- 블록은 다른 엔트리가 블록에 추가되기 전에 디스크 버퍼로부터 불러오게 되며 블록을 다시 디스크에 쓰기 위한 또 다른 디스크 탐색을 유도한다.
				- **그래서 각 엔트리 삽입에 대한 랜덤 읽기와 랜덤 쓰기 연산이 요구된다** 
	- **bulk loading(벌크 로딩)** 
		- 많은 수의 엔트리를 한번에 인덱스에 삽입하는 것
	- **인덱스의 벌크 로딩을 실행하는 효율적인 방법**
		- 릴레이션의 인덱스 엔트리를 포함하는 임시 파일을 생성한다.
		- 그 이후에 구축되는 인덱스의 검색 키에 대해 파일을 정렬하고, 마지막으로 정렬된 파일을 스캔하고 엔트리를 인덱스에 삽입한다.
		- 대용량 릴레이션을 Sorting하는 효율적인 알고리즘은 Query Processing 파트의 Sorting Operation에서 합당한 크기의 메인 메모리가 가능하다는 가정하에 I/O 비용이 파일을 읽을 때와 비교하여 조금 더 시간을 들여 대용량의 파일을 정렬할 수 있다.
	- **엔트리를 B+트리에 삽입하기 전에 정렬하는 장점**
		- 엔트리가 정렬된 순서로 삽입될때, 특정 leaf node에 들어갈 모든 엔트리를 순차적으로 나타날것이고 leaf node는 한번만 작성된다.
		- CASE) B+트리가 빈 상태로 시작된다면 벌크 로딩하는 동안 노드는 디스크로부터 읽힐 필요가 없다.
			- 각 Leaf node는 비록 엔트리가 노드에 삽입되더라도 오직 한번의 I/O 연산만이 일어난다.
- B-트리 인덱스 파일
	- **💡언제 B+트리를 사용하고 언제 B-트리를 사용하시겠나요?** 
	- B+ 트리와 비슷하나 B-트리는 Search Key값이 차지한 중복된 저장 공간을 제거한다는 것이다.
	- 중복제거로 인해서 non leaf node의 Search Key가 나타나지 않는 경우가 있기 때문에 **Non-Leaf Node** 에 각 Search Key를 위한 부가적인 포인터 필드를 포함해야 한다.
		- **부가적인 포인터는 파일 레코드나 관련된 Search Key를 위한 버켓을 가리킨다**
	- B+ 트리는 Leaf Node까지 이동 후 검색 결과를 얻고 B-트리는 Leaf Node에 도달하기 전에 얻을 수 있는 가능성이 높다.
		- B- Tree
			- Leaf Node에 Non Leaf Node보다 약 n배 많은 키를 저장하고 있다.
			- Search Key 중복 제거로 B+ Tree보다 Non Leaf Node에 더 적은 Search Key를 가진다.
				- **B- 트리가 더 적은 팬아웃을 갖고 있음을 의미한다** 
					- B-트리가 B+트리보다 트리의 높이가 더 높다.
		- B+ Tree
			- Non Leaf Node에 중복 Search Key를 허용하기 때문에 B- Tree에 비해 Leaf Node와 Non Leaf Node가 가지는 키 차이가 심하지 않다.
		- 일반적으로 검색 시간은 검색 키 개수의 로그에 비례 한다.
		- 그러나 B- 트리에서 몇몇 검색 키를 찾는 것은 빠르지만 나머지 다른 검색 키를 찾는 데는 더 느리다.
			- 즉, 탐색 성능이 일정하지 않다.
		- B- Tree 삭제의 복잡성
			- B+ Tree는 항상 Leaf Node에 나타나는 반면에 B- Tree는 Non-Leaf Node에 나타날 수 있어서 해당 타겟의 노드의 서브 트리들을 어떻게 처리 해야될지도 고려해야 된다.
- 플래시 저장 장치에서 인덱싱
- 메모리에서 인덱싱



## 해시 인덱스


## 다중 키 접근

## 쓰기 최적화 인덱스 구조




