---
title: 3-트랜스포트 계층
permalink: /cs/network/top-down-approach/3-트랜스포트 계층
tags:
  - Network
layout: page
---

- demultiplexing(디멀티 플렉싱)
	- 트랜스포트 계층 세그먼트의 데이터를 올바른 소켓으로 전달하는 작업.
- multiplexing (멀티 플렉싱)
	- 출발지 host에서 소켓으로부터 데이터를 모으고, 이에 대한 세그먼트를 생성하기 위해 각 데이터에 헤더정보로 캡슐화하고, 그 세그먼트들을 네트워크 계층으로 전달하는 작업.
- 트랜스포트 Layer에서 세그먼트 구성 (TCP/UDP)
	- 출발지 포트 번호, 목적지 포트 번호
	- 헤더들
	- DATA(Application Layer의 Message)
- Layer별 데이터 단위의 이해
	- Application Layer : Message, 구성요소 : 원본 데이터
	- Transport Layer : TCP: Segment / UDP : Datagram, 구성요소 : 전송 계층 Header (TCP/UDP Header + DATA)
	- Network Layer : Packet(패킷), 구성 요소 : 네트워크 계층 헤더(IP Header) + 세그먼트
	- Data Link Layer : Frame(프레임) , 구성 요소 : 데이터 링크 계층 헤더 (MAC Header) + 패킷
- 연결 지향형 멀티플렉싱과 디멀티플렉싱
	- TCP socket
		- *TCP socket identifier는 포트가 아니라 four-tuple을 통해 이루어진다* 
		- four-tuple
			- 출발지 IP주소
			- 출발지 포트 번호
			- 목적지 IP주소
			- 목적지 포트 번호
- rdt1.0
	- finite-state-machine, FSM (유한 상태 머신)
	- *완전히 신뢰적인 채널에서 동작하는 프로토콜.* 
	- 절대적인 packet loss나 data error등이 절대 발생하지 않는다는 가정하에 설계된 전송 프로토콜
- rdt2.0
	- *비트 오류가 있는 채널상에서의 전송 프로토콜.* 
	- *전송된 모든 패킷이 순서대로 수신된다는 가정이 필요* 
	- positive acknowledgment 와 negative acknowledgement 사용.
	- 자동 재전송 프로토콜인 Automatic Repeat reQuest, ARQ 프로토콜.
	- 비트오류를 처리하는게 목적.
	- *ACK나 NAK를 받고 보내기 때문에 stop-and-wait 프로토콜로도 불림* 
	- ARQ 프로토콜 핵심 기능 3가지
		- error detection
			- check sum
		- feedback
			- positive acknowledgement(ACK)와 negative acknowledgement(NAK)를 상요하여 sender에게 피드백을 주는 메커니즘.
		- 재전송
			- 위의 2가지에서 체크섬에러나 NAK을 받으면 sender가 재전송.
	- 단점
		- ACK나 NAK를 수신하고 보내는 stop-and-wait 방식이라 비효율적임.
		- ACK나 NAK 패킷의 손상을 고려하지 않음.
- rdt 2.1
	- sequence number 사용
		- new Transmission(새로운 전송)인지, duplicate Transmission(중복 전송)인지 구별하기 위한 식별 번호
	- ACK(acknowledgement)에 다음 패킷 순서 번호를 포함 함으로써 NAK를 사용안함.
- rdt 3.0
	- 비트 오류와 loss가 있는 채널상에서의 신뢰적인 데이터전송에 사용하는 프로토콜
	- 타이머 사용과 재전송
- pipelining 된 신뢰적인 데이터 전송 프로토콜
	- *stop-and-wait* 방식의 비효율적인 전송 방식의 한계를 극복하기 위한 프로토콜

# TCP

- 마치 reliable한 data 전송을 하는것처럼 application Layer에게 환상을 주는 4가지 메커니즘
	- *error detection*
		- 데이터에 문제가 발생하는것을 detection
	- *feedback*
		- 정상적으로 전송 되었는지
	- *sequnce number*
		- 세그먼트 전송 순서
	- *timer*
		- loss를 방지하고 재전송
- 현실적인 TCP 동작은 Pipelined protocols를 통해서 동작한다.
	- pipelining 방식
		- 두가지 generic한 방법
			- go-Back-N
			- selective repeat
- checksum(체크섬) : 세그먼트에 오류가 발생했는지를 검사하기 위해 receive host가 사용한다.
- 체크섬 Error Detection (오류검출)
	- sender는 데이터를 전송하기전에 checksum을 계산하여 헤더에 포함.
	- 수신자는 도착한 데이터를 바탕으로 checksum을 다시 계산하여, 기존 checksum과 비교
	- 값이 다르다면 데이터가 손상되었다고 판단하고 해당 세그먼트를 무시.
- 체크섬 동작 원리
	- sender는 TCP/UDP 헤더 + 데이터(세그먼트/데이터그램)를 16비트 단위로 나눔.
	- 각 16비트 조각을 더함
	- 결과의 1의 보수를 취한 값을 체크섬(Checksum)필드에 저장.
	- 전송
	- receiver는 도착한 세그먼트/데이터그램을 동일한 방식으로 16비트 단위로 나눔.
	- 모든 16비트 값과 체크섬을 더함.
	- 결과값이 모든 비트가 1이어야 정상적인 데이터로 판별
	- 아니라면 해당 세그먼트 폐기.

# 연결 지향형 TCP

- point-to-point
	- 하나의 sender와 하나의 receiver간의 소켓 한쌍
- reliable, in-order by stream
	- 애플리케이션에서 내려온 메세지가 에러없이 loss없이 전송된다.
	- 애플리케이션에서 내려온 메세지 순서대로 전송된다.
- pipelined
	- TCP congestion(혼잡) and flow(흐름) control로 window size를 설정.
- full duplex data
	- 전이중방향 연결이다.
	- 즉, 각각의 소켓은 sender이면서 receiver이다.
- connection-oriented (연결 지향형)
	- handshaking
- flow controlled (흐름제어)
	- Go-Back-N(GBN)
	- Selective Repeat(SR)
- congestion control (혼잡제어)

## TCP Segment Structure

```
| source port (출발지 포트번호) | dest port (목적지 포트 번호)           |
|             sequence number(순서번호)                            |
|             acknowledgement number (확인 응답번호)                |
| header length | flag field (SYN, FIN, ACK 등) | receive window |
|              Data (application Layer message)                 |
```

- sequence number (순서 번호) : 32bits 필드, reciever 입장에서 해당 세그먼트가 new Transmission(새로운 전송)인지, duplicate Transmission(중복 전송)인지 구별하기 위한 식별 번호
	- 바이트 단위로 시퀀스 번호를 부여합니다.
- acknowledgement number (확인 응답 번호) : negative feedback을 없애는 대신 ACK에 sequence number를 담아서 보낸다.

## TCP seq numbers, ACKs

- sequence numbers
	- *byte 단위로 sequence number를 붙인다* 
	- ex) TCP 세그먼트에서 sequence number를 매길때 100byte라고 했을때 100개의 byte가 있고 그중에서 제일 앞에 있는 녀석을 0번 byte로 하고 0~99번으로 sequence number 번호를 매긴다.
- acknowledgements
	- *seq number* 의 다음 byte 번호를 담아서 응답.
	- ex) 99번까지의 sequence number를 성공적으로 받았고 다음 100번부터의 sequence number를 담아서 전달.


## TCP round trip time, timeout

- segment를 보낼때 timer를 구동 시키고 timer가 익스파이어 되기전까지 feedback이 오지 않으면 재전송.
- Round Trip Time(RTT)을 측정을 해서 조금 여유 있는 + margin을 timer에 적용.
- Round Trip Time을 세그먼트를 매번 보낼때마다 측정한다.
- Round Trip Time을 세그먼트를 보낼때마다 측정 하는데 세그먼트를 보내고 피드백이 올때까지의 시간을 측정한게 Sample Round Trip Time(RTT) (피드백도 결국 세그먼트다)
- 재전송이 발생할 세그먼트는 이 Sample Round Trip Time에 포함시키지 않는다.
	- feedback이 오지 않았을때 재전송을 하기 때문에 이상한값이 포함될 수 있는 가능성이 있기 때문에.

> 매번 segment를 보낼때 측정하는데 Sample Round Trip Time을 측정 해보면 시간이 다르게 나온다.
> 같은 point to point 소켓 한쌍에서 연결형인 상태에서 segment를 보낼때 마다 시간이 동적으로 결과가 나온다.
> 이런이유는 각각 세그먼트가 같은 경로의 라우터를 따라가더라도 큐잉 딜레이가 다르기 때문에
> timer 값을 정하기가 쉽지않다. 즉, 타이머 값은 Round Trip Time + 어느정도의 여유의 margin값인데
> 이를 정하는게 쉽지 않다.

- EstimatedRTT : 위에서의 문제점인 Timer값을 정해주기 위해서 매번 Round Trip Time을 측정 할때마다 갱신 해준다.
	- 가중치를 통해서 Round Trip Time의 측정값에 따라 갱신 해준다. 즉, 최신 Round Trip Time의 가중치를 통해서 갱신해준다.
	- 즉 EstimatedRTT값에 여유 마진 safety margin 값을 더해서 Timer 값을 설정 한다.

## TCP 파이프라인과 제약 (중요)

- 이게 보니까 TCP 연결은 전이중연결로 서로 왔다갔다 하는 연결이기 때문에
- 각각의 소켓은 send buffer와 receive buffer 둘다를 가진다.
- TCP 소켓 연결.
- TCP를 관리하는 소켓당 1개의 Timer를 가짐.
- 한쌍의 TCP 소켓이 연결이 되고나면 2개의 버퍼가 생성이 된다.
- send buffer
- receive buffer
- TCP는 파이프라인을 통해서 하나씩 보내면 효율성이 안좋기 때문에
- 한번에 확 쏟아붙는 파이프라인을 통해서 많은 세그먼트를 전송하는데 이것도 무한대는 아니기 때문에
- 제약이 있다.
- 그 제약이 window size만큼만 한번에 전송 할 수 있다.
- send buffer에서 0~199보냄
- receive buffer에서 받음. ACK에 200번 담아서 응답 전달.
- send buffer에서 ACK 확인 했기 때문에 이제 send buffer에 0~199 지움.
- send base가 뒤로 이동 됨.
	- 원래는 0을 가리키고 있다가 200번을 가리킴.
- window size도 함께 이동 하게 된다.


```ts
// [1번째 상황]
// send buffer 
[0,1,2,3,4,5,6,7,8,9,10]
// buffer base 0
// window size 2
// 0,1번 보냄 

// receive buffer
[0,1]
// 2번 ACK 담아서 receive buffer가 보냄
// 이때 잘 받았으니까 Process B에게 위로 올린다. 오퍼레이션한다

// [2번째상황]
// send buffer
[2,3,4,5,6,7,8,9,10]
// buffer base 2
// window size 2
// 2,3 번 보냄
// 4번 ACK 담아서 receive buffer가 보냄

// receive buffer
[2,3]
```

- send buffer에서 ACK를 받아서 전송에 성공하면 해당 buffer에서 지우는데 그렇다면 send buffer에 저장 해두는 이유는 결국 혹시라도 재전송 하기 위해서.
- 이걸 이제 이해 하면서 TCP segment structure를 보면서 이해하면 된다.
- 유실이 발생 했을때 재전송은 언제 일어날까?
	- 타이머가 익스파이어 될때
		- 그게언제?
			- Estimated RTT + safety margin
- 빨리 유실이 발생 했는지 판단하는 방법은 없을까?
	- TCP fast retransmit
		- 3 ACKs
		- 예를 들어 ACK=100을 3번 받았을때 loss라고 판단.
		- 빠른 재전송을 실시한다.


```ts
// sender buffer
[0,1,2,3,4,5]
receive window : 2
Base : 0
// receive buffer
[]

// Go-Back-N
// 첫번째
// sender
// segement
// seq 0
// data : 0,1

// receiver
[0,1]
// -> ACK -> header: ACK number 2, receive window: 2

// 두번째
// sender buffer
[2,3,4,5]
Base: 2
receive window : 2
segment: seq: 2, data: 2,3

// receive buffer
[0,1,2,3]
// -> ACK -> header: ACK number 4, receive window: 2

```

# Sample problem

- 패킷 교환 다이어그램을 자세히 작성하세요 (예: 순서 번호(seq#), 확인 응답 번호(ack#)) 파일이 완전히 수신될 때까지의 과정을 나타내시오.
- A와 B 사이에 TCP 연결이 확립되었다고 가정합니다.
- 호스트 A는 600바이트 크기의 파일을 전송합니다.
- 첫 번째 데이터 패킷의 순서 번호(seq#) = 300
- 모든 데이터 패킷의 크기 = 100바이트
- 윈도우 크기 = 1000
- 재전송 타임아웃(RTO) = 500ms, 왕복 지연 시간(RTT) = 50ms
- 두 번째 데이터 패킷이 손실됨
- 호스트 A는 빠른 재전송(Fast Retransmit)을 사용함

> 아 이게 보니까 지금 이거 TCP 전송에 대한 그림 자체를 직접 그릴 수 있어야 하네.
> 그림에 이제 send buffer receive buffer , window , ACK

# TCP flow control (흐름제어)

- *흐름 제어(Flow Control)*
	- *클라이언트가 데이터를 너무 빠르게 보내서 서버가 처리할 수 있는 버퍼크기를 초고화지 않도록 조절하는 메커니즘입니다.* 
		- 이걸를 무시하면 어떻게 되나요?
			- *버퍼 오퍼플로우 발생* 
		- 어떻게?
			- TCP는 서버가 처리할 수 있는 데이터양을 수신 Window를 통해서 클라이언트에게 알려줍니다.
			- 핵심은 세그먼트의 header에 receive window로 조절한다.
		- Stop-and-Wait 방식
			- 수신자가 *ACK* 을 보내야만 송신자가 다음 데이터를 전송하는 방식
			- 비효율적인 방식 왜 안쓸까?
				- 한번에 하나의 패킷만 보내고 ACK을 받을때까지 기다리기 때문에.
		- Go-back-N (슬라이딩 윈도우 방식)
			- *TCP에서 한번에 여러개의 패킷을 연속적으로 보내서 ACK를 받은 만큼 Window 크기를 동적조절 새로운 데이터를 전송할 수 있도록 합니다* 
			- 현대 TCP에서 사용하는 방식이다.
			- 문제점
				- Go-back-N은 패킷 하나의 오류 때문에 많은 패킷을 재전송하므로, 많은 패킷을 불필요하게 재전송하는 경우가 발생한다.
		- Selective Repeat (SP)
			- receiver에서 오류가 발생한 패킷을 수신했다고 의심되는 패킷만을 sender가 다시 전송하여 불필요한 재전송을 피하는 메커니즘.
	- 최적화 기법
		- Nagle 알고리즘
		- Delayed ACK
		- David Clock
- Error Control
	- acknowledgment
		- 전송 세그먼트의 순서를 보장 할 수 있다.
	- checksum
		- 잘못된 데이터가 전송 되었는지 확인 할 수 있다.
	- Retransmission(재전송)
		- estimated timer + 여유 marign값이 타이머의 익스파이어 시간이고 타이머가 익스파이어 되기전까지 ACK를 받지 못하면 loss로 판단하고 재전송.
		- fast Retransmission (빠른 재전송)
			- 같은 ACK가 3번오면 타이머가 익스파이어 되기전에 재전송 하는 방식.
	- TCP Deadlock
		- receive window(rwnd)가 0을 보내 sender가 데이터 송신을 멈춘 상태.
		- 해결방법
			- TCP Persist Timer기법
				- 송신자가 주기적으로 아주 작은 window probe 패킷을 보내서 receive window 크기를 확인하는 메커니즘.


- flow control이 필요한 이유가 위의 신뢰적인 전송의 흐름과 연관이 있다.
- 즉, receive buffer에서 성공한 데이터를 APP에서 가져가는 속도보다 send buffer에서 receive buffer의 전송이 너무나 빠르다면? 또는 Read call을 띄엄띄엄 하거나 아니면 아예 안하고 있다면?
- 그러한 흐름을 조절하는게 flow control이고 그 방법으로 APP에서 receive buffer 사이즈가 얼만지 알 수 있기 때문에 그걸 알려주는거다.
- 남아있는 빈공간을 receive window , TCP 세그먼트에 DATA와 Header에서 Header에 해당 receive window 정보가 있다.
- 그니까 send buffer의 window size를 통해서 파이프라이닝 방식으로 세그먼트를 확 보낼 수 있는게 그 사이즈를 조절하는게 Header에 있는 receive window정보를 가지고 조절한다.
- send buffer의 window size가 결국 receive buffer의 receive window를 통해서 제어되기 때문에 오버플로우가 발생하지 않는다.


## 예외 케이스 TCP Persist Timer

- 데드락 상황.
- receive window 가 0일때 이제 안보낸다.
- 그래서 새로운 공간이 생길때까지 안보내게 제어 한다.
- Read call이 발생해서 여유 공간이 만약 생겼을때
- receive window를 상대방에게 알릴 수 있는 방법은 세그먼트를 보내야 알 수 있다.
	- 왜냐하면 세그먼트 Header에 receive window 패킷이 담겨 있으니까.
- *receive window를 상대방에게 알릴 수 있는 2가지 방법* 
	- write call 발생으로 send buffer에 보낼것이 있어서 이제 보낼 수 있는 경우
	- 상대방에서 세그먼트가 들어와서 ACK를 줄때
- 근데 만약에 write를 안하고 있고 받기만 하는 애플리케이션인 상태에서 이미 상대방한테는 receive window가 0으로 알고 있기 때문에 결국 여유 공간이 생겨서 receive window가 널널해져서 그걸 알려야 하는데 그럴 방법이 없어서 데드락 상태인거다.
- 이를 해결 하기 위해서 receive window가 0이라면 알고난 이후에 가만히 있는게 아니라 주기적으로 아주 작은 세그먼트를 보내서 receive window를 확인.

## 하나의 세그먼트 크기

### sender가 어떻게 보낼지에 대한 내용

#### 세그먼트 크기를 최대로 했을때

> 실제 세그먼트 크기는 얼마일까?
> 세그먼트는 Header와 Data로 구성
> Header부분은 40bite로 정해져 있다.
> 세그먼트 사이즈가 크면 클수록 오버헤드가 줄어든다?
> *세그먼트 크기는 크면 클수록 좋은 이유는 오버헤드를 줄일 수 있다* 
> Header 크기는 어차피 고정이기 때문에 DATA 크기를 최대 세그먼트 크기까지해서 보내게 된다면 여러 세그먼트로 나누어서 보내는 횟수가 줄어드므로 결론적으로 오버헤드가 줄어들게된다.
> Send Buffer에 데이터가 언제 들어오는지는 소켓에서 write를 했을때다.

#### write 주기가 느릴때

> 여기서 문제점을 고려해야 되는 상황이 한가지가 바로 write를 천천히 했을때다.
> 이때 세그먼트 크기를 얼마로 해야할까?
> 극단적인 예로 write를 1bite씩 했을때 Send Buffer에도 그렇게 1바이트씩 들어가게 된다.
> 그러면 이때 생각을 해보면 세그먼트 크기를 얼마로 해야할까? Header는 40bite로 고정.
> DATA는 크면 클수록 좋다고 했다. 그러나 write가 극단적으로 조금씩 write한다면 이때 굉장히 높은 오버헤드가 발생할것이다. 왜? 보낼 send buffer에 DATA를 가득 채워두고 한번에 확 보내는 파이프라이닝 방식으로 하면 최대 세그먼트 크기 즉, 최대 window size만큼 보낼 수 있어서 오버헤드를 줄일 수 있는데 1bite씩 보낸다면?
> 그만큼 보내는 횟수가 증가하면서 오버헤드가 증가하는것이다.
> *즉, write 크기가 작을수록 Header가 차지하는 비율이 커져서 오버헤드가 높다* 
> 보낼때 1bite밖에 없다면 모으고 보내는게 훨씬 좋기 떄문에

##### 해결방법

- Nagle's Algorithm (나이글 알고리즘)
	- send buffer에 채워지는 양이 천천히 채워지고 있다면 이것이 어느정도까지 기다렸다가 보내야할지 정하기가 확실하지 않기 때문에 이문제를 해결하기 위해서 등장한 알고리즘.
- 원리
	- 첫번째 세그먼트는 크기가 어떻게 되더라도 담아서 우선 보낸다.
	- 전송 후 feedback이 올때까지 채워진 send buffer의 크기가 max 세그먼트 사이즈를 초과 한다면 feedback이 도착하기 전에 전송.
	- 전송 후 feedback이 도착 할때 send buffer의 크기가 천천히 채워져서 크기가 작더라도 feedback이 도착하면 그냥 전송.
- 왜 좋은가?
	- 전송 후 feedback을 받을동안 send buffer에 어느정도 채워져있다면 그만큼 기다릴 가치가 있다는걸 알 수 있다.
	- 전송 후 feedback을 받을 동안 send buffer에 매우 작은 크기밖에 채워지지 않았다면 기다릴 가치가 없다는걸 알 수 있다.
	- 전송후 feedback이 오기전에 send buffer의 크기가 max 세그먼트 사이즈를 초과 했을때 보내기 떄문에 효율적이다.
- 알 수 있는것
	- 세그먼트 크기
		- 애플리케이션이 생성하는 속도가 네트워크 상황 속도 즉, 보내고 받는 속도 보다 빠르면 즉, 애플리케이션에서 write를 통해서 send buffer에 쌓는 속도가 더 빠른경우를 의미한다.
			- 세그먼트 사이즈가 커진다.
		- 반대로 애플리케이션에서 write를 통해서 send buffer에 쌓는 속도가 더 느린 경우, 네트워크 상황 속도인 보내고 받는 속도가 더 빠르다는 소리 (네트워크 상황이 좋다는걸 의미한다)
			- 세그먼트 사이즈가 작아진다.
				- 오버헤드가 증가한다.
				- 하지만 네트워크 상황이 좋다는뜻이기 떄문에 오버헤드가 증가하여 비효율적으로 전송하더라도 충분히 보낼 수 있다.


```
TCP는 이런 **작은 write로 인한 오버헤드를 줄이기 위해** **Nagle’s Algorithm**을 사용합니다.

- **작은 데이터를 즉시 전송하지 않고, 일정량 모아서 한 번에 전송하는 방식**입니다.
- 즉, **Send Buffer에 충분한 데이터가 모일 때까지 기다렸다가 묶어서 전송**합니다.
- 하지만, **지연(Latency)이 중요한 경우(TCP_NODELAY 설정)** 이 알고리즘을 비활성화할 수도 있습니다.
```

#### write를 하고 Send buffer에 데이터가 쌓인 후

- *write를 하고 send buffer에 데이터가 쌓이는데 이때 언제 보내는지?*  
	- 바로 ACK를 수신 했을때 ACK를 수신 해서 다음 보낼 send buffer의 번호를 통해서 보냄.
	- 얼만큼 보내는지가 바로 Header에 있는 receive window값을 통해서 전송양을 조절할 수 있다.
	- 그렇다면 보낼때 항상 최대 세그먼트를 보내는게 좋을까?
		- 최대 window size만큼 보낼수록 오버헤드가 낮아지기 때문에 좋다.
			- 왜냐?
				- 보내는 세그먼트는 Header와 DATA로 구성되어 있는데
				- Header는 40bite로 고정된 크기를 가지기 때문에 DATA크기가 최대크기만큼 보내면
				- 그만큼 보내는 횟수를 줄일 수 있어서 오버헤드를 줄일 수 있다.

#### 언제 데이터를 보내는가? (TCP Send Buffer에서 데이터 전송 조건)

- TCP는 **애플리케이션이 write()를 호출하면** 데이터를 Send Buffer에 저장한 후, 다음 조건에 따라 데이터를 전송합니다:
    1. **ACK를 받았을 때** → 새로운 데이터를 보낼 수 있는 윈도우 크기 확인 후 전송.
    2. **윈도우 크기가 허용하는 만큼 데이터가 준비되었을 때** → 윈도우 크기를 초과하지 않는 범위에서 데이터 전송.
    3. **타이머 기반 송신** → Nagle's Algorithm이 활성화된 경우, 작은 데이터는 일정 시간 동안 모아서 전송.
    4. **Push 플래그(PSH)가 설정된 경우** → 애플리케이션이 `TCP_NODELAY` 옵션을 사용하면 즉시 전송.


### receiver 측 내용

- David Clark
	- Receive buffer가 꽉 찼을때 receive window가 0인건 맞다.
	- Receive buffer의 어느정도 빈공간이 있더라도 receive window를 0이라고 설정해도 괜찮다.
	- 만약에 Receive buffer가 1bite만 남았다면?
	- receive window가 1bite로 전송이 되고 송신측에서 전송할때 1bite만 보내게 되는 현상이 발생.
	- *Receive buffer의 빈공간이 maximum 세그먼트 사이즈보다 작으면 그냥 receive window를 0이라고 설정해서 보내자.* 
- Delayed ACK
	- 원래 TCP의 동작은 세그먼트를 receive하면 송신측에 ACK를 즉시 해줘야 한다.
	- 세그먼트를 받은후에 ACK를 잠시만 기다렸다가 해보자.
	- 500ms만큼만 기다렸다가 ACK를 하자.
	- 왜?
		- 혹시라도 해당 다음 세그먼트가 올까봐.
		- 즉, 핵심은 다음에 보낼 세그먼트 번호인 ACK를 보낼 필요가 줄어들 수 있다.
		- 예를 들어 1~100 세그먼트를 보내고 receive buffer에서 받았는데 원래는 바로 ACK에 101을 담아서 보내줘야 하지만 500ms만큼 잠깐 기다렸는데 만약 101~200이 왔다면 ACK 101을 보낼 필요가 없어진다.
		- 결국 기다리는 시간만큼 또 다른 세그먼트가 오면 다시 500ms만큼 또 기다리고 하다보면 ACK를 보내는 횟수가 대폭 줄어들 수 있다.
		- 1~100의 세그먼트가 왔는데 ACK를 바로 안하면 어떻게 송신측에서 101번의 세그먼트를 보낼 수 있는거지?
			- *TCP에서 송신측에서 보낼때 다음 세그먼트를 보내는 기준이 ACK만 보고 데이터를 보내는것이 아니다 즉, 가장 헷갈리는 부분이지만 중요한 부분이 처음에 보낼때 Receive window(rwnd) 값을 바탕으로 최대 몇개의 세그먼트를 보낼 수 있는지 미리 계산한다* 
			- 그니까 만약에 Receive window(rwnd)가 1000이라면
			- 송신측에서 1~100의 세그먼트를 보내고 수신측에서 500ms 정도 기다리는동안 송신측에서 101~200을 보낼 수 있는거다.


# connection management

## 연결

- 2-way handshake
	- 2-way 방식으로 하게 되었을때 먼저 보낸 송신측은 응답을 받을 수 있으나 수신측에서는 송신측의 확인 응답을 받을 수 없다.
- 3-way-handshake
	- SYN
		- *헤더의 필드가 정말 이해하는게 중요하다* 
	- *중요한점*  
		- 첫번째 host A에서 host B에 연결 요청을 보내는 SYN=1, seq=client_isn
		- 두번째 host B에서 host A로 보내는 SYN=1, seq=server_isn, ack=client_isn+1
		- *Header* 만 전송한다는게 중요하다.
		- 세번째 SYN ACK에 대한 ACK는 실제로 보내고자 하는 DATA를 담아서 보낼 수 있다.

## 해제

- 4-way-handshake
	- *TCP가 보낼 데이터가 이제 더이상 없을때 FIN을 보내면서 연결을 해제 하는데 데이터가 없는건 어떻게 알까?* 
		- 보낼 데이터가 없다는걸 결정 하는것은 TCP가 아니라 애플리케이션이다.
		- *애플리케이션에서 close 콜을 한다* 
	- Finish (FIN)
		- host A의 애플리케이션에서 *close 콜을한다* 
		- 보낼 데이터가 없다는 신호로 FIN을 host B에 보낸다.
	- ACK
	- Finish (FIN)
		- host B도 애플리케이션에서 더이상 보낼 데이터가 없을때 *close 콜을한다* 
		- host A에게 FIN을 보낸다.
	- ACK
- host A에서 ACK를 마지막으로 받고 연결이 종료 되었을때 바로 해제하는게 아니라 한동안은 OS에서 그대로 보관한다. 이를 TIME_WAIT라고 한다.
- TIME_WAIT란?
	- 4-way-handshake 과정에서 마지막으로 ACK를 전송한 호스트(A)는 연결을 바로 해제 하지 않고 일정 시간동안 TIME_WAIT 상태에서 기다린다.
	- 왜 이렇게 하나?
		- 재전송 방지
			- 마지막 ACK 패킷이 손실되었다고 가정 하면 상대방 host(B)가 FIN을 재전송 할 수 도 있다.
			- 즉, TCP는 FIN에 대한 ACK가 확실히 도착했는지 확인하기 위해서 일정시간(TIME_WAIT)를 유지한다.
			- host B에서 타이머 키고 FIN을 보냈는데 유실 되면 다시 재전송을 하기 위해서고 그리고 만약에 host A가 바로 해제를 했을때 마지막 ACK를 host B에 보내주는데 여기서 마지막 ACK가 유실되었을 경우에 원래는 host A가 재전송을 해야 하지만 연결 해제 해서 없기 때문에 결국 다시 host B가 계속 FIN을 보내는 현상이 발생하게 된다. 


- . *혼잡 제어(Congestion Control)* 
	- *네트워크가 과부하 상태에 빠지는 것을 방지하기 위해 TCP가 전송 속도를 조절하는 메커니즘입니다.* 
	- 왜 필요하죠?
	- 네트워크 Latency 증가
	- 잦은 데이터 재전송시의 네트워크 대역폭 낭비
		- *Slow Start*
			- *처음에는 적은 데이터부터 전송하며 점진적으로 증가*
		- *Congestion Avoidance* 
			- 특정 임계값에 도달하면 증가 속도를 일정하게 조절합니다.
		- Fast Recovery (빠른 회복)
			- 패킷 손실이 감지되면 빠르게 복구
	- 무한버퍼 라우터 
- TCP Congestion Control (혼잡제어) 알고리즘 3가지 구성
	- slow start
	- congestion avoidance (혼잡 회피)
	- fast recovery (빠른 회복)

# TCP congestion control (혼잡제어)

- 네트워크간의 혼잡이 발생하지 않도록 TCP가 전송 속도를 조절하는 메커니즘.
- 네트워크가 처리할 수 있는 양보다 더 많은 데이터가 들어왔을때 생기는 현상
- 네트워크의 congestion이 발생하지 않는 최대치를 찾아보자라는게 congestion control의 목적.
- additive increase
- multiplicative decrease

## 시나리오
- 시나리오 1 - 2개의 sender와 무한 버퍼를 갖는 하나의 라우터
- 시나리오 2 - 2개의 sender와 유한 버퍼를 갖는 하나의 라우터
- 시나리오 3 - 4개의 sender와 유한 버퍼를 갖는 라우터, 그리고 멀티홉 경로 

## congestion control에 대한 접근법

- end to end congestion control (종단간 혼잡 제어)
- 네트워크 delay 혼잡 제어


## TCP에서 congestion control

- 네트워크 혼잡에 따라 연결에 트래픽을 보내는 전송률을 각 sender가 제한하도록 하는것이다.
- 의문점
	- TCP 송신자는 자신의 연결에 송신자 전송 트래픽 전송률을 어떻게 제한하는가?
		- 전송률을 제어하는 congestion window(cwnd)값을 조정하는 메커니즘.
		- *추가적인 변수인 congestion window(혼잡 윈도)를 통해서 추적한다* 
			- congestion window는 TCP에 존재 하지 않고 송신자의 OS의 TCP 스택에서 자동 관리한다.
	- TCP 송신자는 자신과 목적지 사이 경로의 혼잡을 어떻게 감지 하는가?
		- 타임아웃 또는 3ACKs수신이 발생 했을때
		- loss event라고 판단하고 재전송. 예를들면 Go-back-N방식으로 과도한 재전송으로 인하여
		- route에 있는 하나 이상의 router buffer들이 overflow되면 이때 TCP 데이터 그램이 버려진다.
		- 이때 버려진 데이터 그램은 송신 측에서 loss event라고 판단하고 또 다시 재전송.
		- 송신자와 수신자간의 route상의 혼잡이 발생 했음을 알게 된다.
	- 송신자는 종단간 혼잡을 감지함에 따라 송신율을 변화시키기 위해서 어떤 알고리즘을 사용 해야 하는가?
	- *TCP는 어떻게 송신자가 자신이 송신할 속도를 결정 하는가?* 
		- 손실된 세그먼트는 혼잡을 의미하며, 이에 따라 TCP 전송률은 한 세그먼트를 손실 했을 때 줄여야 한다.
		- 확인응답된 세그먼트는 네트워크가 송신자의 세그먼트를 수신자에게 전송된다는 것이고, 이에 따라 이전에 확인 응답되지 않은 세그먼트에 대해 ACK가 도착하면 송신자의 전송률은 증가할 수 있다.
		- 대역폭 탐색
	- 위의 3가지 개념을 바탕으로 *TCP congestion-control algorithm* 을 사용한다.
- TCP congestion-control algorithm
	- *Additive Increase, Multiplicative Decrease (AIMD)* 기반.
	- *slow-start*
		- 작게 보내면서 점진적으로 증가하는 방식.
		- slow-start가 종료되는 3가지
			- 첫번째
				- loss event 발생시에 congestion window 값을 다시 1로 설정하고 다시 처음부터 slow-start한다.
				- *TCP 2번째 추가된 상태 변수 slow start threshold* 값을 congestion window값의 반으로 설정한다.
			- 두번째
				- congestion window값과 slow start threshold 값이 같아지면 종료된다.
				- *TCP는 congestion avoid(혼잡 회피)* 상태로 전환한다.
			- 세번째
				- 3개의 중복 ACK가 검출되면 TCP는 빠른 재전송과 빠른 회복 상태로 들어간다.
	- *Congestion Avoidance (혼잡 회피)*
		- 혼잡 회피 상태에 들어가면 congestion window값은 마지막 혼잡 시점에서의 값의 반이 된다.
		- TCP는 Round Trip Time마다 하나의 Max Segment Size만큼 congestion window값을 증가 시킨다.
		- 새로운 ACK가 도착 할때마다 TCP 송신자가 congestion window 값을 Max Segment Size만큼 증가 시킨다.
			- ex) MSS가 1,460 바이트 cwnd가 14,600바이트일때 10개의 세그먼트가 한 RTT내에서 송신 될 수 있다.
		- *언제 Avoidance 선형 증가가 끝나나?* 
			- 3ACKs 일때
				- congestion window값을 반으로 줄이고 show start threshold값을 congestion window값의 반으로 기록.
				- 이후 빠른 회복상태가 된다.
			- timer expire 즉, 타임 아웃이 발생 했을때
				- 다음 어떻게 되나?
					- congestion window값을 1로 설정하고 slow start threshold 값을 loss event가 발생 했을 때의 cwnd값의 반으로 설정하고 다시 slow-start로 돌아가게된다.
	- *Fast Recovery (빠른 복구)*
		- 3ACKs 를 수신 할때 congestion window값을 반으로, slow start threshold 값을 cnwd값의 반으로 기록하고 빠른 복구 상태가 된다.
- TCP Tahoe(TCP 타호)
	- TCP 초기 버전
	- timeout이거나 3ACKs로 표시되는 loss가 발생하면 무조건 congestion window값을 1로 줄이고, slow-start 단계로 들어간다.
	- *Avoidance, Fast Recovery가 없는 초기 버전* 
- TCP Reno (TCP 리노)
	- TCP 새로운 버전
	- slow-start로 시작
	- congestion window와 slow start threshold값이 같아지면 혼잡 회피상태가 된다.
	- TCP Reno에서는 3ACKs로 인한 loss event 발생시 Fast Recovery를 사용한다.
- TCP 큐빅
	- 리눅스 TCP 기본 버전이기도 하다.
	- *Avoidance 선형 증가가 끝나는 타임 아웃이 발생 했을때 congestion window 값을 1로 설정하고 slow start threshold 값을 cnwn값의 반으로 설정* 하는 방식이 비효율적이기 때문에 등장.
	- ACK 수신시에만 congestion window를 늘리고 slow-start와 Fast Recovery는 동일하게 유지.
	- congestion Avoidance 단계가 수정되었다.
		- congestion window를 세제곱 함수로 증가시킨다.

## congestion

> threshold(ssthresh)는 OS의 TCP 스택에서 관리되는 변수이다.
> 사용자가 컨트롤 하는 즉, user thread에서 조작하는게 아니라 kernel thread가 내부적으로 동적으로 변경됨.
> TCP 소켓마다 개별적으로 관리된다.

- Slow Start, Congestion Avoidance, threshold(ssthresh)
- TCP에서 feedback, ACK로 판단한다.
- TCP에서는 어떻게 congestion window를 control 하나?
	- 세그먼트를 보내고 그것에 대한 제대로 된 feedback을 받으면 segment size만큼 congestion window를 하나 늘립니다.
- 이전의 언급대로 세그먼트는 크면 클수록 좋다. 그것이 maximum segment size이다.
- 이제 congestion 문제가 발생 했을때 문제가 발생하면 congestion window 사이즈를 반으로 줄인다.
- congestion 문제에는 어떤게 있을까?
	- 네트워크상에서 전송에서 TCP 소켓의 한쌍은 하나가 아니라 여러개이기 때문에 만약 네트워크상에서 네트워크 대역폭이 부족한 경우
	- 너무 많은 sender로 인한 네트워크 과부하
	- 라우터의 처리 한계 초과
		- 패킷이 한꺼번에 너무 많이 몰려서 라우터의 큐가 가득차서 패킷 Drop이 발생.
	- sender가 receive의 속도를 고려하지 않고 무리하게 데이터를 보내면 congestion 문제 발생.
- 왜?
	- congestion window size는 천천히 조심스럽게 늘려야 하기 때문에 해당 TCP 연결 소켓 한쌍만 쓰는게 아니기 때문이다.
- 제일 처음의 congestion window size는 어떻게 정할까?
	- TCP Slow Start
		- 제일 처음 세그먼트를 1개만 보낸다.
- 처음에 Slow Start로 시작하자가 어떠한 기준을 기점으로 기존의 TCP 전송 방식을 따른다.
	- 메커니즘 자체가 비슷한것이 결국 기준이 되는 *Threshold*  값 기준으로 slow start에서 Congestion Avoidance 방식으로 전환된다.
- sender 기준으로 Loss를 판단하는 기준 2가지
	- Timer expire
	- 3 Duplicate ACKs (3Dup ACKs)
- sender 기준에서 해당 판단 기준에 해당하게 된다면 더이상 많이 보내지 않고 congestion window (cwnd) 사이즈를 반으로 줄이는것이다.
- Timer expire와 3Dup ACKs일때의 congestion 상태가 다를까? 어떤것이 더 congestion할까?
	- 3Dup ACKs 상황
		- loss이지만 중간의 하나의 세그먼트가 loss되어서 뒤의 세그먼트들이 ACK를 3번 보낸 상황이다. 즉, loss이긴 하지만 치명적이지는 않다.
	- Timer expire 상황
		- 분명히 여러 세그먼트들중에서 뒤의 세그먼트가 3Dup ACKS 상황이 될텐데 Timer expire 된 상황은 그냥 전체가 loss가 되어버린 상황으로 치명적인 상황이다.
- 이런 상황에서 sender 기준에서의 Loss가 발생 했을때의 congestion 문제가 발생 하였을때 처리하는것이 동일하게 처리하면 효율적이지 못하다.
- TCP Tahoe(타호)에서는 congestion 문제가 발생 하면 다시 slow start로 시작한다.
- TCP Reno(리노)에서는 3Dup ACKs 상황에서 더 효율적으로 처리하기 위해서 Threshold 값과 Congestion window 값을 반으로 줄이고 Linear Increment로 다시 시작.
	- 이 과정을 *Fast Recovery(빠른 복구)* 라고 한다.


# TCP throughput

- 전송 속도를 결정하는것은 네트워크가 결정.
- 즉, 고정된것이 아니다. 네트워크 상황에 따라 달라진다.
- UDP의 전송 속도는 애플리케이션이 결정한다.
- TCP의 congestion control이 없다면 어떻게 될까?
	- fairness goal
		- 총 2쌍의 TCP 소켓이 있을때 전송 속도가 1/2 씩 속도를 가지게 된다.
		- 어떻게?
			- TCP를 사용하면 어떻게 1/N씩 fair하게 사용 하는것은 Congestion control의 역할로 이루어지는데
			- 2개의 TCP 커넥션이 처음에 slow start로 시작하면서 점점 증가하다가 congestion window 증가 
			- Threshold값에 도달하면 2개의 TCP 커넥션이 둘다 Threshold값과 Congestion window값이 절반으로 줄이고 다시 Linear increment로 시작.
			- 이 과정을 반복하다보면 2개의 TCP 커넥션의 전송속도가 fair하게 동작하게 된다.




